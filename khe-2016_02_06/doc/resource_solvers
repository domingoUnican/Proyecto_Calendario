@Chapter
    @Title { Resource Solvers }
    @Tag { resource_solvers }
@Begin
@LP
A @I { resource solver } assigns resources to tasks, or changes
existing resource assignments.  This chapter presents the resource
solvers packaged with KHE.
@BeginSections

@Section
    @Title { Specification }
    @Tag { resource_solvers.spec }
@Begin
@LP
The recommended interface for resource solvers, defined in
@C { khe.h }, is
@ID @C {
typedef bool (*KHE_TASKING_SOLVER)(KHE_TASKING tasking,
  KHE_OPTIONS options);
}
It assigns resources to some of the tasks of @C { tasking },
influenced by @C { options }, returning @C { true } if
it changed, or at least usually changes, the solution.
Taskings were defined in Section {@NumberOf extras.taskings}.
@PP
Except for preassignments, there is no reason to assign resources,
at least in large numbers, before times are assigned.  Accordingly,
a resource solver may choose to assume that all meets have been
assigned times.  It may alter time assignments in its quest for
resource assignments.
# @PP
# One example of a resource solver is @C { KheSolnAssignPreassignedResources }
# from Section {@NumberOf solutions.complete}.  It ensures that all preassigned
# tasks of the given type (or of all types) are assigned
# their preassigned values.  It does not assume that times are assigned.
@PP
A @I { split assignment } is an assignment of two or more distinct
resources to the tasks monitored by an avoid split assignments monitor.
A @I { partial assignment } is an assignment of resources to some of these
same tasks, but not all.  An assignment can be both split and partial.
# @PP
# The author's previous resource solvers @Cite { $kingston2008resource }
# are either for @I { teacher assignment }, where the event resources
# are assumed to have avoid split assignments constraints, or for
# @I { room assignment }, where they are assumed not to.  Since XML
# instances may apply any number of avoid split assignments constraints
# of any weight to any event resources, the algorithms presented here
# hybridize these previous methods.  It is important, however, not to
# lose sight of the distinction, because it is far easier to assign
# resources when there are no avoid split assignments constraints.
@End @Section

@Section
    @Title { The resource assignment invariant }
    @Tag { resource_solvers.invt }
@Begin
@LP
If all tasks have duration 1, then the matching defines an assignment
of resources to tasks which maximizes the number of assignments.
Although larger durations are common, and maximizing the number of
assignments is not the only objective, still it is clear from this
fact that the matching deserves a central place in resource assignment.
@PP
Accordingly, the author's work in resource assignment
@Cite { $kingston2008resource } emphasizes algorithms that preserve the
following condition, called the @I { resource assignment invariant }:
@ID @I {
The number of unmatchable demand tixels equals its initial value.
}
Assignments are permitted only when the number of unmatchable demand
tixels does not increase.  This keeps the algorithms on a path that
cannot lead to new violations of required avoid clashes constraints,
avoid unavailable times constraints, limit busy times constraints,
and limit workload constraints.  In practice, most tasks can be
assigned while preserving this invariant.
@PP
The invariant is not usually checked after each individual operation.
Rather, a sequence of related operations is carried out, and then
the number of unmatchable demand tixels at the end of the sequence
is compared with the number at the start.  If it has increased, the
sequence of operations needs to be undone.  Such sequences were called
@I { atomic sequences } in Section {@NumberOf solutions.marks},
where the following code (using a mark object) was recommended
for obtaining them:
@ID @C {
mark = KheMarkBegin(soln);
success = SomeSequenceOfOperations(...);
KheMarkEnd(mark, !success);
}
When preserving the resource invariant, this needs to be changed to
@ID @C {
mark = KheMarkBegin(soln);
init_count = KheSolnMatchingDefectCount(soln);
success = SomeSequenceOfOperations(...);
if( KheSolnMatchingDefectCount(soln) > init_count )
  success = false;
KheMarkEnd(mark, !success);
}
This works even without the matching, since then
@C { KheSolnMatchingDefectCount } returns 0.
@PP
As a simple but effective aid to getting this right, this code is
encapsulated in functions
@ID @C {
void KheAtomicOperationBegin(KHE_SOLN soln, KHE_MARK *mark,
  int *init_count, bool resource_invariant);
bool KheAtomicOperationEnd(KHE_SOLN soln, KHE_MARK *mark,
  int *init_count, bool resource_invariant, bool success);
}
which may be placed before and after a sequence of operations, like
this:
@ID @C {
KheAtomicOperationBegin(soln, &mark, &init_count, resource_invariant);
success = SomeSequenceOfOperations(...);
KheAtomicOperationEnd(soln, &mark, &init_count, resource_invariant,
  success);
}
Here @C { mark } and @C { init_count } are variables of type
@C { KHE_MARK } and @C { int }, not used for anything else,
@C { resource_invariant } is @C { true } if the operations must
preserve the resource invariant to be considered successful, and
@C { success } is their diagnosis of their own success, not including
checking the resource invariant.  @C { KheAtomicOperationEnd }
returns @C { true } if @C { success } is @C { true } and
(if @C { resource_invariant } is @C { true }) the number of
unmatchable demand tixels did not increase:
@IndentedList

@LI -1px @Break @C {
void KheAtomicOperationBegin(KHE_SOLN soln, KHE_MARK *mark,
  int *init_count, bool resource_invariant)
{
  *mark = KheMarkBegin(soln);
  *init_count = KheSolnMatchingDefectCount(soln);
}
}

@LI -1px @Break @C {
bool KheAtomicOperationEnd(KHE_SOLN soln, KHE_MARK *mark,
  int *init_count, bool resource_invariant, bool success)
{
  if( resource_invariant &&
      KheSolnMatchingDefectCount(soln) > *init_count )
    success = false;
  KheMarkEnd(*mark, !success);
  return success;
}
}

@EndList
The code is trivial, but useful because it encapsulates a common but
slightly confusing pattern.
@PP
If the resource invariant is being enforced, there may be no need
to include the cost of demand monitors in the solution cost, since
their cost cannot increase.  They must continue to monitor the
solution, however, so detaching is not appropriate.  Function
@ID {0.98 1.0} @Scale @C {
void KheDisconnectAllDemandMonitors(KHE_SOLN soln, KHE_RESOURCE_TYPE rt);
}
disconnects all demand monitors (or all demand monitors which
monitor entities of type @C { rt }, if @C { rt } is non-@C { NULL })
from all their parents, including the solution object if it is
a parent.  Thus, as required, they continue to monitor the
solution, but the costs they compute are not added to the
cost of any group monitor.  @C { KheSolnMatchingDefectCount }
still works, however, and there is nothing to prevent them from
being made children of other group monitors later.
@End @Section

#@Section
#    @Title { The resource assignment invariant (old) }
#    @Tag { resource_solvers.invt }
#@Begin
#@LP
#If all tasks have duration 1, then the matching defines an assignment
#of resources to tasks which maximizes the number of assignments.
#Although larger durations are common, and maximizing the number of
#assignments is not the only consideration, still it is clear from this
#fact that the matching deserves a central place in resource assignment.
#@PP
#Accordingly, the author's recent work in resource assignment
#@Cite { $kingston2008resource } emphasizes algorithms that preserve the
#following condition, called the @I { resource assignment invariant }:
#@ID @I {
#The number of unmatchable demand tixels equals its initial value.
#}
#Assignments are permitted only when the number of unmatchable demand
#tixels does not increase.  This keeps the algorithms on a path that
#cannot lead to new violations of required avoid clashes constraints,
#avoid unavailable times constraints, limit busy times constraints,
#and limit workload constraints.  In practice, most tasks can be
#assigned while preserving this invariant.
#@PP
#The invariant is not checked after each individual operation.
#Rather, a sequence of related operations is carried out, and then
#the number of unmatchable demand tixels at the end of the sequence
#is compared with the number at the start.  If it has increased, the
#sequence of operations needs to be undone.  Such sequences were called
#@I { atomic sequences } in Section {@NumberOf solutions.transactions},
#where the following code (using a transaction object ) was recommended
#for obtaining them:
#@ID @C {
#KheTransactionBegin(t);
#success = SomeSequenceOfOperations(...);
#KheTransactionEnd(t);
#if( !success )
#  KheTransactionUndo(t);
#}
#When preserving the resource invariant, this needs to be changed to
#@ID @C {
#KheTransactionBegin(t);
#init_count = KheSolnMatchingDefectCount(soln);
#success = SomeSequenceOfOperations(...);
#if( KheSolnMatchingDefectCount(soln) > init_count )
#  success = false;
#KheTransactionEnd(t);
#if( !success )
#  KheTransactionUndo(t);
#}
#This works even without the matching, since then
#@C { KheSolnMatchingDefectCount } returns 0.
#@PP
#As a simple but effective aid to getting this right, KHE offers functions
#@ID @C {
#void KheAtomicTransactionBegin(KHE_TRANSACTION t, int *init_count,
#  bool resource_invariant);
#bool KheAtomicTransactionEnd(KHE_TRANSACTION t, int *init_count,
#  bool resource_invariant, bool success);
#}
#which may be placed before and after a sequence of operations, like
#this:
#@ID @C {
#KheAtomicTransactionBegin(t, &init_count, resource_invariant);
#success = SomeSequenceOfOperations(...);
#KheAtomicTransactionEnd(t, &init_count, resource_invariant, success);
#}
#They make the intervening sequence of operations atomic by doing what
#the code above does.  Here @C { t } is a transaction not currently in
#use for anything else, @C { &init_count } points to an integer variable
#not currently in use for anything else, @C { resource_invariant } is
#@C { true } if the atomic transaction must preserve the resource
#invariant in order to be considered successful, and @C { success }
#is the intervening sequence of operations' diagnosis of its own
#success or failure, not including checking the resource invariant.
#@C { KheAtomicTransactionEnd } returns @C { true } if @C { success }
#is @C { true } and (if @C { resource_invariant } is @C { true }) the
#number of unmatchable demand tixels did not increase.  Here is the
#implementation:
#@IndentedList
#
#@LI -1px @Break @C {
#void KheAtomicTransactionBegin(KHE_TRANSACTION t, int *init_count,
#  bool resource_invariant)
#{
#  KHE_SOLN soln;
#  soln = KheTransactionSoln(t);
#  *init_count = KheSolnMatchingDefectCount(soln);
#  KheSolnMatchingMarkBegin(soln);
#  KheTransactionBegin(t);
#}
#}
#
#@LI -1px @Break @C {
#bool KheAtomicTransactionEnd(KHE_TRANSACTION t,
#  int *init_count, bool resource_invariant, bool success)
#{
#  KHE_SOLN soln;
#  soln = KheTransactionSoln(t);
#  KheTransactionEnd(t);
#  if( resource_invariant &&
#      KheSolnMatchingDefectCount(soln) > *init_count )
#    success = false;
#  if( !success )
#    KheTransactionUndo(t);
#  KheSolnMatchingMarkEnd(soln, !success);
#  return success;
#}
#}
#
#@EndList
#Opportunity has been taken to optimize the matching by calling
#@C { KheSolnMatchingMarkBegin } and @C { KheSolnMatchingMarkEnd }
#(Section {@NumberOf matchings.setup}).
#@PP
#If the resource invariant is being enforced, there may be no need
#to include the cost of demand monitors in the solution cost, since
#their cost cannot increase.  They must continue to monitor the
#solution, however, so detaching is not appropriate.  Function
#@ID {0.98 1.0} @Scale @C {
#void KheDisconnectAllDemandMonitors(KHE_SOLN soln, KHE_RESOURCE_TYPE rt);
#}
#disconnects all demand monitors (or all demand monitors which
#monitor entities of type @C { rt }, if @C { rt } is non-@C { NULL })
#from all their parents, including the solution object if it is
#a parent.  Thus, as required, they continue to monitor the
#solution, but the costs they compute are not added to the
#cost of any group monitor.  @C { KheSolnMatchingDefectCount }
#still works, however, and there is nothing to prevent them from
#being made children of other group monitors later.
#@End @Section

@Section
    @Title { Resource-structural solvers }
    @Tag { resource_solvers.structural }
@Begin
@LP
A @I { resource-structural solver } is a solver that changes how
tasks are organized, rather than actually assigning resources.
Arguably, the solvers presented in this section really belong
in Chapter {@NumberOf structural_solvers}, but the structural
solvers presented there are basically about time, not resources.
@BeginSubSections

@SubSection
    @Title { Task bound groups }
    @Tag { resource_solvers.task_bound_groups }
@Begin
@LP
Task domains are reduced by adding task bound objects to tasks
(Section {@NumberOf solutions.tasks.domains}).  Frequently, task
bound objects need to be stored somewhere where they can be found and
deleted later.  The required data structure is trivial---just an array
of task bounds---but it is convenient to have a standard for it, so
KHE defines a type @C { KHE_TASK_BOUND_GROUP } with suitable operations.
@PP
To create a task bound group, call
@ID @C {
KHE_TASK_BOUND_GROUP KheTaskBoundGroupMake(void);
}
To add a task bound to a task bound group, call
@ID @C {
void KheTaskBoundGroupAddTaskBound(KHE_TASK_BOUND_GROUP tbg,
  KHE_TASK_BOUND tb);
}
To visit the task bounds of a task bound group, call
@ID {0.96 1.0} @Scale @C {
int KheTaskBoundGroupTaskBoundCount(KHE_TASK_BOUND_GROUP tbg);
KHE_TASK_BOUND KheTaskBoundGroupTaskBound(KHE_TASK_BOUND_GROUP tbg, int i);
}
To delete a task bound group, including deleting all the task
bounds in it, call
@ID @C {
bool KheTaskBoundGroupDelete(KHE_TASK_BOUND_GROUP tbg);
}
This function returns @C { true } when every call it makes to
@C { KheTaskBoundDelete } returns @C { true }.
@End @SubSection

@SubSection
    @Title { Task trees }
    @Tag { resource_solvers.task_trees }
@Begin
@LP
What meets do for time, tasks do for resources.  A meet has a time
domain and assignment; a task has a resource domain and assignment.
Link events constraints cause meets to be assigned to other meets;
avoid split assignments constraints cause tasks to be assigned to
other tasks.
@PP
There are differences.  Tasks lie in meets, but meets do not lie
in tasks.  Task assignments do not have offsets, because there is
no ordering of resources like chronological order for times.
@PP
Since the layer tree is successful in structuring meets for
time assignment, let us see what an analogous tree for structuring
tasks for resource assignment would look like.  A layer tree is
a tree, whose nodes each contain a set of meets.  The root node
contains the cycle meets.  A meet's assignment, if present, lies
in the parent of its node.   By convention, meets lying outside
nodes have fixed assignments to meets lying inside nodes, and
those assignments do not change.
@PP
A @I { task tree }, then, is a tree whose nodes each contain a set of
tasks.  The root node contains the cycle tasks (or there might be
several root nodes, one for each resource type).  A task's
assignment, if present, lies in the parent of its node.  By
convention, tasks lying outside nodes have fixed assignments to
tasks lying inside nodes, and those assignments do not change.
@PP
Type @C { KHE_TASKING } is KHE's nearest equivalent to a task
tree node.  It holds an arbitrary set of tasks, but there is
no support for organizing taskings into a tree structure, since
that does not seem to be needed.  It is useful, however, to look
at how tasks are structured in practice, and to relate this to
task trees, even though they are not explicitly supported by KHE.
@PP
A task is assigned to a non-cycle task and fixed, to implement an
avoid split assignments constraint.  Such tasks would therefore
lie outside nodes (if there were any).  When a solver assigns a
task to a cycle task, the task would have to lie in a child node
of a node containing the cycle tasks (again, if there were any).
So there are three levels:  a first level of nodes containing
the cycle tasks; a second level of nodes containing unfixed tasks
wanting to be assigned resources; and a third level of fixed,
assigned tasks that do not lie in nodes.
@PP
This shows that the three-way classification of tasks presented
in Section {@NumberOf solutions.tasks.asst}, into cycle tasks,
unfixed tasks, and fixed tasks, is a proxy for the missing task
tree structure.  Cycle tasks are first-level tasks, unfixed tasks
are second-level tasks, and fixed tasks are third-level tasks.
@C { KHE_TASKING } is only needed for representing second-level
nodes, since tasks at the other levels do not require assignment.
By convention, then, taskings will contain only unfixed tasks.
@End @SubSection

@SubSection
    @Title { Task tree construction }
    @Tag { resource_solvers.task_tree.construction }
@Begin
@LP
KHE offers a solver for building a task tree holding the tasks
of a given solution:
@ID @C {
void KheTaskTreeMake(KHE_SOLN soln, KHE_TASK_JOB_TYPE tjt,
  KHE_OPTIONS options);
}
Like any good solver, this function has no special access to data
behind the scenes.  Instead, it works by calling basic operations
and helper functions:
@BulletList

@LI {
It calls @C { KheTaskingMake } to make one tasking for each resource
type of @C { soln }'s instance, and it calls @C { KheTaskingAddTask }
to add the unfixed tasks of each type to the tasking it made for that type.
These taskings may be accessed by calling @C { KheSolnTaskingCount }
and @C { KheSolnTasking } as usual, and they are returned in an order
suited to resource assignment, as follows.  Taskings for which
@C { KheResourceTypeDemandIsAllPreassigned(rt) } is @C { true }
come first.  Their tasks will be assigned already if
@C { KheSolnAssignPreassignedResources } has been called, as it
usually has been.  The remaining taskings are sorted by decreasing
order of @C { KheResourceTypeAvoidSplitAssignmentsCount(rt) }.
These functions are described in Section {@NumberOf resource_types}.
Of course, the user is not obliged to follow this ordering.  It is
a precondition of @C { KheTaskTreeMake } that @C { soln } must have
no taskings when it is called.
}

@LI {
It calls @C { KheTaskAssign } to convert resource preassignments into
resource assignments, and to satisfy avoid split assignments constraints,
as far as possible.  Existing assignments are preserved (no calls to
@C { KheTaskUnAssign } are made).
}

@LI {
It calls @C { KheTaskAssignFix } to fix the assignments it makes.
These may be removed later.
}

@LI {
It calls @C { KheTaskSetDomain } to set the domains of tasks to
satisfy preassigned resources, prefer resources constraints, and
other influences on task domains, as far as possible.
@C { KheTaskTreeMake } never adds a resource to any domain, however;
it either leaves a domain unchanged, or reduces it to a subset of
its initial value.
}

# @LI {
# It calls @C { KheTaskDomanFix } to fix the domains it sets.
# These fixes may be removed later if required.
# }

# @LI {
# If { 0.95 1.0 } @Scale @C { check_prefer_resources_monitors } is
# @C { true }, it applies { 0.95 1.0 } @Scale @C { KheMonitorAttach Check }
# to each prefer resources monitor which monitors any affected task,
# consistent with the attachment and grouping invariant
# (Section {@NumberOf grouping.conventions}).
# }

# @LI {
# If { 0.95 1.0 } @Scale @C { check_avoid_split_assignments_monitors } is
# @C { true }, it applies { 0.95 1.0 } @Scale @C { KheMonitorAttach Check }
# to each avoid split assignments monitor which monitors any affected task,
# consistent with the attachment and grouping invariant
# (Section {@NumberOf grouping.conventions}).
# }

@EndList
These elements interact in ways that make them impossible to
separate.  For example, a prefer resources constraint that
applies to one task effectively applies to all the tasks that
are linked to it, directly or indirectly, by avoid split
assignments constraints.  The two parameters not yet mentioned,
@C { tjt } and @C { options }, are explained below.
@PP
The implementation of @C { KheTaskTreeMake } has two stages.  The
first creates one tasking for each resource type of @C { soln }'s
instance, in the order described, and adds to each the unfixed tasks
of its type.  This stage can be carried out separately by repeated
calls to
@ID @C {
KHE_TASKING KheTaskingMakeFromResourceType(KHE_SOLN soln,
  KHE_RESOURCE_TYPE rt);
}
which makes a tasking containing the unfixed tasks of @C { soln } of
type @C { rt }, or of all types if @C { rt } is @C { NULL }.  It
aborts if any of these unfixed tasks already lies in a tasking.
@PP
The second stage is more complex.  It applies public function
@ID @C {
bool KheTaskingMakeTaskTree(KHE_TASKING tasking, KHE_TASK_JOB_TYPE tjt,
  KHE_TASK_BOUND_GROUP tbg, KHE_OPTIONS options);
}
to each tasking made by the first stage.  When @C { KheTaskingMakeTaskTree }
is called from within @C { KheTaskTreeMake }, its parameters other than
@C { tasking } are inherited from @C { KheTaskTreeMake }.
@PP
As specified for @C { KheTaskTreeMake }, @C { KheTaskingMakeTaskTree }
assigns tasks and tightens domains; it does not unassign tasks or
loosen domains.  If @C { tbg } is non-@C { NULL }, any task bounds
created while tightening domains are added to @C { tbg }.  If the
@C { resource_invariant } option of @C { options }
is @C { true }, only assignments and tightenings that preserve the
resource assignment invariant (Section {@NumberOf resource_solvers.invt})
are kept.  Tasks assigned to non-cycle tasks have their assignments fixed,
and cease to be unfixed tasks, so are deleted from @C { tasking }.
@PP
The implementation of @C { KheTaskingMakeTaskTree } imitates the layer
tree construction algorithm:  it applies @I jobs in decreasing priority
order.  There are fewer kinds of jobs, but the situation is more complex
in another way:  sometimes, some kinds of jobs are wanted but not others.
The three kinds of jobs of highest priority install existing domains and
task assignments, and assign resources to unassigned tasks derived from
preassigned event resources.  These jobs are always included; the first
two always succeed, and so does the third unless the user has made
peculiar task or domain assignments earlier.  The other kinds of jobs
are optional, and parameter @C { tjt } of @C { KheTaskingMakeTaskTree }
says which of them are wanted.  Its type is
@ID @C {
typedef enum {
  KHE_TASK_JOB_HARD_PRC = 1,
  KHE_TASK_JOB_SOFT_PRC = 2,
  KHE_TASK_JOB_HARD_ASAC = 4,
  KHE_TASK_JOB_SOFT_ASAC = 8,
  KHE_TASK_JOB_PARTITION = 16
} KHE_TASK_JOB_TYPE;
}
As the reader has probably guessed, @C { tjt } is actually a set.
@PP
If @C { KHE_TASK_JOB_HARD_PRC } is included in @C { tjt }, a job
is made for each point of application of each required prefer
resources constraint of non-zero weight.  The priority of the
job is the combined weight of its constraint, and it attempts
to reduce the domains of the tasks of @C { tasking } monitored
by the constraint's monitors so that they are subsets of the
constraint's domain.  @C { KHE_TASK_JOB_SOFT_PRC } is the same,
except that it requests jobs for non-required constraints.
@PP
If @C { KHE_TASK_JOB_HARD_ASAC } is included in @C { tjt }, a job
is made for each point of application of each hard avoid split
assignments constraint of non-zero weight.  Its priority is the
combined weight of its constraint, and it attempts to assign
tasks to each other so that all the tasks of the job's point
of application of the constraint are assigned, directly or
indirectly, to the same root task.  Again, only tasks lying
in @C { tasking } are affected.  @C { KHE_TASK_JOB_SOFT_ASAC }
is the same, except that it requests jobs for soft constraints.
@PP
If @C { KHE_TASK_JOB_PARTITION } is included in @C { tjt },
a very peculiar job, of minimal priority, is included.
The remainder of this section is devoted to explaining it.
@PP
We begin by explaining the circumstances in which it is useful.
For definiteness, suppose we are dealing with teachers, and that
they have partitions (Section {@NumberOf resource_types}) which
are their faculties (English, Mathematics, Science, and so on).
Some partitions may be heavily loaded (that is, required to
supply teachers for tasks whose total workload approaches the
total available workload of their resources) while others are
lightly loaded.
@PP
Some tasks may be taught by teachers from more than one partition.
These @I { multi-partition tasks } should be assigned to teachers from
lightly loaded partitions, and so should not overlap in time with
other tasks from these partitions.  @C { KHE_TASK_JOB_PARTITION }
tightens the domain of each multi-partition task to one partition;
the choice of partition is explained below.  It is best to do this
after preassigned meets have been assigned, but before general time
assignment.  The tightened domains encourage time assignment to
avoid the undesirable overlaps.
@PP
After time assignment, the changes should be removed, since
otherwise they constrain resource assignment unnecessarily.
A task bound group can be used to do this:
@ID @C {
tighten_tbg = KheTaskBoundGroupMake(soln);
for( i = 0;  i < KheSolnTaskingCount(soln);  i++ )
  KheTaskingTightenToPartition(KheSolnTasking(soln, i),
    tighten_tbg, options);
... assign times ...
KheTaskBoundGroupDelete(tighten_tbg);
}
@C { KheTaskingTightenToPartition }, defined below,
wraps a call to @C { KheTaskingMakeTaskTree }.
@PP
This job does nothing when the tasking has no resource type,
or the tasks of its resource type are all preassigned
according to @C { KheResourceTypeDemandIsAllPreassigned }
(Section {@NumberOf resource_types}), or the resource type has
no partitions, or its number of partitions is less than four
or more than one-third of its number of resources.  Nothing useful
can be done in these cases.
@PP
Tasks whose domains lie entirely within one partition are not touched.
The remaining multi-partition tasks are sorted by decreasing combined
weight then duration, except that tasks with a @I { dominant partition }
come first.  A task with an assigned resource has a dominant partition,
namely the partition that its assigned resource lies in.  An unassigned
task has a dominant partition when at least three-quarters of the
resources of its domain come from that partition.
@PP
For each task in turn, an attempt is made to tighten its domain so
that it is a subset of one partition.  If the task has a dominant
partition, only that partition is tried.  Otherwise, the partitions
that the task's domain intersects with are tried one by one, stopping
at the first success, after sorting them by decreasing average
available workload (defined next).
@PP
Define the @I { workload supply } of a partition to be the sum, over
the resources @M { r } of the partition, of the number of times in
the cycle minus the number of workload demand monitors for @M { r }
in the matching.  Define the @I { workload demand } of a partition
to be the sum, over all tasks @M { t } whose domain is a subset of
the partition, of the workload of @M { t }.  Then the
@I { average available workload } of a partition is its workload
supply minus its workload demand, divided by its number of resources.
Evidently, if this is large, the partition is lightly loaded.
@PP
Each successful tightening increases the workload demand of its
partition.  This ensures that equally lightly loaded partitions
share multi-partition tasks equally.
@PP
In a task with an assigned resource, the dominant partition is the
only one compatible with the assignment.  In a task without an
assigned resource, preference is given to a dominant partition, if
there is one, for the following reason.  Schools often have a few
@I { generalist teachers } who are capable of teaching junior
subjects from several faculties.  These teachers are useful for
fixing occasional problems, smoothing out workload imbalances,
and so on.  But the workload that they can give to faculties other
than their own is limited and should not be relied on.  For
example, suppose there are five Science teachers plus one
generalist teacher who can teach junior Science.  That should
not be taken by time assignment as a licence to routinely schedule
six Science meets simultaneously.  Domain tightening to a dominant
partition avoids this trap.
@PP
Tightening by partition works best when the @C { resource_invariant }
option of @C { options } is @C { true }.  For example, in a case like
Sport where there are many simultaneous multi-partition tasks, it
will then not tighten more of them to a lightly loaded partition
than there are teachers in that partition.  Assigning preassigned
meets beforehand improves the effectiveness of this check.
@End @SubSection

@SubSection
    @Title { Other task tree solvers }
    @Tag { resource_solvers.task_tree.reorganization }
@Begin
@LP
This section documents some miscellaneous functions that reorganize
task trees, represented by taskings.  They assume that only unfixed
tasks lie in taskings, and they preserve this condition.  Some
merely call @C { KheTaskingMakeTaskTree }, passing certain
combinations of parameters; others are separate algorithms.
@PP
The operation of tightening domains to a partition was discussed
at some length above.  For convenience, this operation is packaged
as function
@ID @C {
bool KheTaskingTightenToPartition(KHE_TASKING tasking,
  KHE_OPTIONS options);
}
It tightens the domains of some tasks, without any wholesale
reconstruction of the task tree:
@ID @C {
bool KheTaskingTightenToPartition(KHE_TASKING tasking,
  KHE_OPTIONS options)
{
  return KheTaskingMakeTaskTree(tasking, KHE_TASK_JOB_PARTITION,
    options);
}
}
It is best if the @C { resource_invariant } option of @C { options }
is @C { true } here.
# The call to @C { KheTaskingMakeTaskTree } asks for the resource
# assignment invariant to be preserved (best here), but not for prefer
# resources monitors to be checked.  Any tightening of domains
# introduces the theoretical possibility that some prefer resources
# monitors could be safely detached, but there are likely to be few
# cases here.  Also, monitor attaching and unattaching operations
# are currently not captured by transactions, so reattaching them
# later could be messy.
@PP
A good way to minimize split assignments is to prohibit them at
first but allow them later.  To change a tasking from the first
state to the second, call
@ID @C {
void KheTaskingAllowSplitAssignments(KHE_TASKING tasking,
  bool unassigned_only);
}
It unfixes and unassigns all tasks assigned to the tasks of
@C { tasking } and adds them to @C { tasking }.  If one of
the original unfixed tasks is assigned (to a cycle task), the
tasks assigned to it are assigned to that task, so that existing
resource assignments are not forgotten.  If @C { unassigned_only }
is @C { true }, these actions are only applied to the unassigned
tasks of @C { tasking }.  (This option is included for completeness,
but it is not recommended, since it leaves few choices open.)
# @C { KheMonitorAttach Check } is applied
# to each affected avoid split assignments monitor, so that the cost
# of any split assignments created later will not be overlooked.
@C { KheTaskingAllowSplitAssignments } preserves the resource
assignment invariant.
@PP
If any room or any teacher is better than none, then it will
be worth assigning any resource to tasks that remain unassigned
at the end of resource assignment.  Function
@ID { 0.98 1.0 } @Scale @C {
void KheTaskingEnlargeDomains(KHE_TASKING tasking, bool unassigned_only);
}
permits this by enlarging the domains of the tasks of @C { tasking }
and any tasks assigned to them (and so on recursively) to the full
set of resources of their resource types.  If @C { unassigned_only }
is true, only the unassigned tasks of @C { tasking } participate in
these changes.  The tasks are visited in postorder---that is, a task's
domain is enlarged only after the domains of the tasks assigned to it
have been enlarged---ensuring that the operation cannot fail.
# this next function withdrawn, it's too error-prone, in this form anyway
# Function
# @ID @C {
# void KheSolnResetDomains(KHE_SOLN soln, KHE_RESOURCE_TYPE rt);
# }
# returns the domain of each task @C { task } derived from an event
# resource @C { er }, or each task of the given resource type if @C { rt }
# is non-@C { NULL }, to @C { KheEventResourceHardDomain(er) }, the
# original value assigned by @C { KheEventInSolnMakeCompleteRepresentation };
# but only in so far as this does not contradict any current assignments.
@End @SubSection

@SubSection
    @Title { Task groups }
    @Tag { resource_solvers.task_groups }
@Begin
@LP
There are cases where two tasks are interchangeable as far as
resource assignment is concerned, because they demand the same
kinds of resources at the same times.  The @I { task group }
embodies KHE's approach to taking advantage of interchangeable tasks.
@PP
The @I { full task set } of an unfixed task is the task itself and all
the tasks assigned to it, directly or indirectly (all its followers),
omitting tasks that do not lie in a meet.  An unfixed task is
@I { time-complete } if each task of its full task set lies in a
meet that has been assigned a time.  Two time-complete tasks are
@I { time-equal } if their full task sets have equal cardinality,
and the two sets can be sorted so that corresponding tasks have
equal starting times, durations, and workloads.  Two unfixed tasks
are @I interchangeable if they are time-complete and time-equal,
and their domains are equal.  When two resources are assigned to
two interchangeable tasks, either resource can be assigned to
either task and it does not matter which is assigned to which.
@PP
A @I { task group } is a set of pairwise interchangeable tasks.
Task groups occur naturally when there are linked events, or when
time assignments are regular.  Virtually any resource assignment
algorithm can benefit from task groups.  Assigning to a task group
rather than to a task eliminates symmetries that can slow down
searching.  A given resource can only be assigned to one task of
a task group, since its tasks overlap in time, so task groups help
with estimating realistically how many resources are available,
and how much workload is open to a resource.
@PP
Objects of type @C { KHE_TASK_GROUP } hold one set of interchangeable
tasks, and objects of type @C { KHE_TASK_GROUPS } hold a set of task
groups.  Such a set can be created by calling
@ID @C {
KHE_TASK_GROUPS KheTaskGroupsMakeFromTasking(KHE_TASKING tasking);
}
It places every task of @C { tasking } into one task group.
The task groups are maximal.
# @C { KheTaskGroupsMakeFromTasking } begins by calling
# @C { KheTaskingSortForTaskGroups }, a public function (not elsewhere
# documented) which sorts the tasks of @C { tasking } and the tasks
# of those tasks in a way that makes the job of
# @C { KheTaskGroupsMakeFromTasking } easy.  The tasks
# of each task are sorted so that tasks whose solution
# events have an assigned time come first.  Among tasks
# with an assigned time, those with earlier times precede those with
# later times.  The tasks of @C { tasking } are then sorted to bring
# interchangeable tasks together.
@PP
To remove a set of task groups (but not their tasks), call
@ID @C {
void KheTaskGroupsDelete(KHE_TASK_GROUPS task_groups);
}
To access the task groups, call
@ID { 0.98 1.0 } @Scale @C {
int KheTaskGroupsTaskGroupCount(KHE_TASK_GROUPS task_groups);
KHE_TASK_GROUP KheTaskGroupsTaskGroup(KHE_TASK_GROUPS task_groups, int i);
}
To access the tasks of a task group, call
@ID @C {
int KheTaskGroupTaskCount(KHE_TASK_GROUP task_group);
TASK KheTaskGroupTask(KHE_TASK_GROUP task, int i);
}
There must be at least one task in a task group, otherwise the task
group would not have been made.  Task groups are not kept up to date
as the solution changes, so if time assignments are being altered
the affected tasks cannot be relied upon to remain interchangeable.
@PP
The tasks of a task group have the same total duration, total
workload, and domain, and these common values are returned by
@ID @C {
int KheTaskGroupTotalDuration(KHE_TASK_GROUP task_group);
float KheTaskGroupTotalWorkload(KHE_TASK_GROUP task_group);
KHE_RESOURCE_GROUP KheTaskGroupDomain(KHE_TASK_GROUP task_group);
}
@C { KheTaskGroupTotalDuration } is the value of
@C { KheTaskTotalDuration } shared by the tasks, not the sum of
their durations; and similarly for @C { KheTaskGroupTotalWorkload }.
@PP
For the convenience of algorithms that use task groups, function
@ID @C {
int KheTaskGroupDecreasingDurationCmp(KHE_TASK_GROUP tg1,
  KHE_TASK_GROUP tg2);
}
is a comparison function that may be used to sort task groups
by decreasing duration.
@PP
Because the tasks of a task group are interchangeable, it does not
matter which of them is assigned when assigning resources to them.
This makes the following functions possible:
@ID @C {
int KheTaskGroupUnassignedTaskCount(KHE_TASK_GROUP task_group);
bool KheTaskGroupAssignCheck(KHE_TASK_GROUP task_group, KHE_RESOURCE r);
bool KheTaskGroupAssign(KHE_TASK_GROUP task_group, KHE_RESOURCE r);
void KheTaskGroupUnAssign(KHE_TASK_GROUP task_group, KHE_RESOURCE r);
}
@C { KheTaskGroupUnassignedTaskCount } returns the number of
unassigned tasks in @C { task_group }; @C { KheTaskGroupAssignCheck }
checks whether @C { r } can be assigned to a task of @C { task_group }
(by finding the first unassigned task and checking there);
@C { KheTaskGroupAssign } is the same, only it actually makes
the assignment, using @C { KheTaskAssign }, if it can; and
@C { KheTaskGroupUnAssign } finds a task of @C { task_group }
currently assigned @C { r }, and unassigns that task.
@PP
The tasks of a task group may have different constraints, in which
case assigning one may change the solution cost differently from
assigning another.  This is handled heuristically as follows.
The first time @C { KheTaskGroupAssign } returns @C { true }, it
tries assigning @C { r } to each task of the task group, notes
the solution cost after each, and sorts the tasks into increasing
order of this cost.  Then it and all later calls assign the first
unassigned task in this order.
@PP
The usual debug functions are available:
@ID { 0.97 1.0 } @Scale @C {
void KheTaskGroupDebug(KHE_TASK_GROUP task_group, int verbosity,
  int indent, FILE *fp);
void KheTaskGroupsDebug(KHE_TASK_GROUPS task_groups, int verbosity,
  int indent, FILE *fp);
}
print @C { task_group } and @C { task_groups } onto @C { fp }
with the given verbosity and indent.
@End @SubSection

@EndSubSections
@End @Section

@Section
    @Title { Most-constrained-first assignment }
    @Tag { resource_solvers.most_constrained_first }
@Begin
@LP
When each unfixed task has no followers, so that each demands a
resource for a single interval of time, as is usual with room
assignment, a simple `most constrained first' heuristic
assignment algorithm that maintains the resource assignment
invariant is usually sufficient to obtain a virtually optimal
assignment.  Function
@ID @C {
bool KheMostConstrainedFirstAssignResources(KHE_TASKING tasking,
  KHE_OPTIONS options);
}
implements this algorithm.  It attempts to assign each unassigned
unfixed task of @C { tasking }, leaving assigned ones untouched.  For
each such task, it maintains the set of resources that can currently
be assigned to the task without increasing the number of unmatchable
demand tixels.  It repeatedly selects a task with the fewest number
of such resources, assigns it if possible, and repeats until all
tasks have been handled.
@PP
The chosen assignment must preserve the resource assignment
invariant.  If no resources satisfy that condition, the task
remains unassigned.  Among all resources that satisfy it, as
a first priority a resource whose assignment minimizes
@C { KheSolnCost } is chosen, and as a second priority,
resources that have already been assigned to other tasks of the
event resources of the task and the tasks assigned to it are
preferred.  In this way, even when an avoid split assignments
constraint is not present, the algorithm favours assigning the same
resource to all the tasks of a given event resource, for regularity.
@PP
In fact, @C { KheMostConstrainedFirstAssignResources } assigns
task groups (Section {@NumberOf resource_solvers.task_groups}),
not individual tasks.  Each task of a task group is assignable
by the same resources, so one list of suitable resources is kept
per task group.  At each step, a task group is selected for
assignment for which the number of suitable resources minus the
number of unassigned tasks is minimal.
@PP
When a resource is assigned to a task, it becomes less available, so
its suitability for assignment to its other task groups is rechecked.
If it proves to be no longer assignable to some of them, their
priorities are changed.  The task groups are held in a priority queue
(Appendix {@NumberOf modules.priqueue}), which allows their queue
positions to be updated efficiently when their priorities change.
@End @Section

@Section
    @Title { Resource packing }
    @Tag { resource_solvers.pack }
@Begin
@LP
To @I pack a resource means to find assignments of tasks to the
resource that make the solution cost as small as possible, while
preserving the resource assignment invariant, in effect utilizing
the resource as much as possible @Cite { $kingston2008resource }.
Function
@ID @C {
bool KheResourcePackAssignResources(KHE_TASKING tasking,
  KHE_OPTIONS options);
}
assigns resources to the unassigned tasks of @C { tasking } using
resource packing, as follows.
@PP
The tasks are clustered into task groups
(Section {@NumberOf resource_solvers.task_groups}).  Two numbers
help to estimate the difficulty of utilizing a resource effectively:
the @I { demand duration } and the @I { supply duration }.  A
resource's demand duration is the total duration of the task groups
it is assignable to.  Its supply duration is the number of times it
is available for assignment:  the cycle length, minus the number of
its workload demand monitors, minus the total duration of any tasks
it is already assigned to.
@PP
The resources are placed in a priority queue, ordered by
increasing demand duration minus supply duration.  That is,
the less demand there is for the resource, or the more supply,
the more important it is to pack it sooner rather than later.
In practice, part-time teachers come first in this order, which
is good, because they are difficult to utilize effectively.
@PP
The main loop of the algorithm removes a resource of minimum
priority from the priority queue and packs it.  If this causes
any task groups to become completely assigned, they are unlinked
from the resources assignable to them, reducing those resources'
demand durations and thus altering their position in the priority
queue.  This is repeated until the queue is empty.
@PP
Each resource @C { r } is packed using a binary tree search:  at
each tree node, one available task group is either assigned to
@C { r }, or not.  The task groups are taken in decreasing order
of the maximum, over all tasks @C { t } of the task group, of
@C { KheMeetDemand(m) }, where @C { m } is the first unfixed meet
on the chain of assignments out of the meet containing @C { t }.
This gives preference to tasks whose meets are hard to move,
reasoning that the leftovers will be given split assignments, and
repairing them may require moving their meets.  The search tree
has a moderate depth limit.  At the limit, the algorithm switches
to a simple heuristic which assigns as many tasks as it can.
@End @Section

@Section
    @Title { Split assignments }
    @Tag { resource_solvers.split }
@Begin
@LP
After solver functions such as
@C { KheMostConstrainedFirstAssignResources }
(Section {@NumberOf resource_solvers.most_constrained_first}) and
@C { KheEjectionChainRepairResources }
(Section {@NumberOf resource_solvers.ejection }) have assigned
resources to most tasks, some tasks may remain unassigned.  These will
have to receive split assignments.  Function
@ID @C {
bool KheFindSplitResourceAssignments(KHE_TASKING tasking,
  KHE_OPTIONS options);
}
reduces the cost of the solution as much as it can, by making split
assignments to the unassigned tasks of @C { tasking } while maintaining
the resource assignment invariant.  Any tasks which were unassigned to
begin with are replaced in @C { tasking } by their child tasks.
@PP
At the core of @C { KheFindSplitResourceAssignments } is a procedure
which takes every pair of resources capable of constituting a split
assignment to some task and tries to assign them greedily to the task,
keeping the assignment that produces the lowest solution cost.  However,
before entering on that, @C { KheFindSplitResourceAssignments }
eliminates resources that cannot be assigned even to one child task,
makes assignments that are forced because there is only one available
resource (not forgetting that one forced assignment might lead
to another, or that once a resource has been assigned to one
child task it makes sense to assign it to as many others as
possible), and divides each task into independent components
(in the sense that no resource is assignable to two components).
In practice, much of what it does is more or less forced.
@End @Section

#@Section
#    @Title { Residual assignments }
#    @Tag { resource_solvers.residual }
#@Begin
#@LP
#@I { Probably omit this now; use ejection chains instead,
#as part of KheTaskingAssignResources }
#@PP
#At the very end of resource assignment, there is a need to
#finish off by making whatever assignments reduce the solution
#cost, irrespective of how split they are or whether they
#maintain the resource assignment invariant.  Function
#@ID @C {
#void KheFindResidualResourceAssignments(KHE_TASKING tasking);
#}
#does this.  It replaces all the unassigned grouped tasks of
#@C { tasking } by their component tasks, then collects these
#unassigned tasks and sorts them by decreasing workload, and
#by increasing domain size when workloads are equal.
#@PP
#It makes three passes over the unassigned tasks.  In the first
#pass, it tries to assign one of the resources lying within each
#task's domain while maintaining the resource assignment invariant.
#In the second pass, it tries to assign one of the resources lying
#in each task's domain, without trying to maintain the invariant.
#In the third pass, it enlarges each remaining task's domain to
#the entire set of resources of the task's type, and tries to
#assign one of those resources, again without trying to maintain
#the invariant.  In each pass it retains the best assignment, if
#there is one which reduces the cost of the solution.
#@PP
#Before enlarging a domain, @C { KheFindResidualResourceAssignments }
#ensures that the prefer resources constraints that monitor the task
#are attached to the solution and grouped somewhere (anywhere) under
#the solution (that is, it attaches and groups them as required).
#Thus they will be sure to report the cost of assigning outside the
#usual domain.
#@End @Section

@Section
    @Title { Kempe and ejecting task moves }
    @Tag { resource_solvers.kempe }
@Begin
@LP
# Suppose all meets are assigned times.  Make a graph with one node
# for each task of some tasking, and join two nodes with an edge when
# their tasks overlap in time.  The problem of assigning resources to
# these tasks, assuming the time assignments stay fixed, is a graph
# colouring problem on this graph, with one colour for each resource,
# subject to various additional constraints.
# @PP
# Suppose we try to assign a resource to some task and find that all of
# the acceptable resources are in use in clashing tasks.  A Kempe chain
# applied to this problem would attempt to exchange certain tasks assigned
# to two resources, to free up a resource.  This is not likely to work
# well for the resource assignment application, although one can't
# be sure without trying it.  Function @C { KheResourcePairReassign }
# (Section {@NumberOf resource_solvers.pair.basic}) is a more
# plausible expression of this basic idea.
# @PP
# The first step in the Kempe chain is to assign the resource and
# unassign any clashing tasks.  This operation will be called an
# @I { ejecting task move }.  Some other method, for example
# ejection chains, can be used to reassign the unassigned
# tasks to whatever resources are available.
# @PP
KHE offers several functions in the area of Kempe and ejecting meet
moves (Section {@NumberOf time_solvers.kempe}), but at present
there is only one function in the area of Kempe and ejecting
task moves:
@ID @C {
bool KheTaskEjectingMoveResource(KHE_TASK task, KHE_RESOURCE r);
}
This attempts to move @C { task } to @C { r }, unassigning @C { r }
from all clashing tasks, and returns @C { true } if it succeeds.
Unlike the functions for ejecting meet moves, it does not consult
the matching, nor does it require the presence of any group monitor.
Instead, it works as follows.
@PP
It calls @C { KheResourceHardUnavailableTimeGroup(r) }
(Section {@NumberOf resources_resources}) to determine when @C { r }
is unavailable, returning @C { false } if @C { task } is running at
any of those times.  Next, by consulting @C { r }'s timetable monitor
at the times of @C { task }, it finds the tasks assigned @C { r } that
clash with @C { task } and unassigns @C { r } from them.  If any cannot
be unassigned (because they are fixed or preassigned), it returns
@C { false }.  Finally, it calls @C { KheTaskMoveResource(task, r) }
and returns what it returns.
@PP
Failed ejecting task moves leave the solution in its state at the
point of failure, so need to be used with marks.  Ejecting task
moves do not attempt to preserve the resource assignment
invariant, leaving that to higher-level solvers.
# @PP
# An interesting question is whether simply assigning @C { r } to
# @C { task } would be sufficient for an ejection chain algorithm,
# leaving the unassignments to the next step in the chain.  The
# problem is that the assignment of @C { r } can introduce
# several defects:  demand defects, avoid clashes defects, and
# workload limit defects.  It is hard to make it clear to an
# algorithm that all of these might be removable by a single
# unassignment.  And then, on the other hand, the only way to
# remove the new clashes is to do these unassignments.  Since
# there are no alternative repairs, it is overkill to use an
# ejection chain to do them; it is better to make them part
# of the original operation.
@End @Section

@Section
    @Title { Ejection chain repair }
    @Tag { resource_solvers.ejection }
@Begin
@LP
Function
@ID @C {
bool KheEjectionChainRepairResources(KHE_TASKING tasking,
  KHE_OPTIONS options);
}
uses ejection chains (Chapter {@NumberOf ejection}) to improve the
solution by changing the assignments of the tasks of @C { tasking }.
For full details, consult Section {@NumberOf ejection.repair}.
@End @Section

@Section
    @Title { Resource pair repair }
    @Tag { resource_solvers.pair }
@Begin
@LP
One idea for repairing resource assignments is to unassign all tasks
assigned to two resources, then try to reassign those tasks to the
same two resources in a better way---an example of very large-scale
neighbourhood (VLSN) search @Cite { $ahuja2002, $meyers2007 }.  The
search space, although formally exponential in size, is often small
enough to search completely, giving an optimal result.
@BeginSubSections

@SubSection
    @Title { The basic function }
    @Tag { resource_solvers.pair.basic }
@Begin
@LP
The basic function for carrying out this kind of repair is
@ID @C {
bool KheResourcePairReassign(KHE_SOLN soln, KHE_RESOURCE r1,
  KHE_RESOURCE r2, bool resource_invariant, bool fix_splits);
}
It knows that when one task is assigned to another, the two tasks
must be assigned the same resource; and it believes that tasks that
overlap in time must be assigned different resources.  It does not
change task domains, fixed assignments, or assignments of tasks to
non-cycle tasks.  If it can find a reassignment to @C { r1 } and
@C { r2 } of the tasks currently assigned to @C { r1 } and @C { r2 }
which satisfies these conditions and gives @C { soln } a lower cost,
it makes it and returns @C { true }; otherwise it changes nothing and
returns @C { false }.  If @C { resource_invariant } is @C { true }, only
changes that preserve the resource assignment invariant are allowed.
@C { KheResourcePairReassign } accepts any resources, but it is most
likely to succeed on resources with similar capabilities that are
involved in defects.
@PP
If @C { fix_splits } is @C { true }, the algorithm focuses on repairing
split assignments, by forcing tasks unassigned by the algorithm which
are linked by avoid split assignments constraints of non-zero cost to
be assigned the same resource in the reassignment.  This runs faster,
because it has fewer choices to try, but it may overlook other kinds
of improvements.
@PP
Within the set of tasks assigned to @C { r1 } and @C { r2 } originally,
there may be subsets which are not assignable to two resources
without introducing clashes.  Clashes in the original assignments
can cause this, as can split assignments when @C { fix_splits } is
set.  Such subsets are ignored by @C { KheResourcePairReassign };
their original assignments are left unchanged.
@End @SubSection

@SubSection
    @Title { A resource pair solver }
    @Tag { resource_solvers.pair.solver }
@Begin
@LP
Resource solver
@ID @C {
bool KheResourcePairRepair(KHE_TASKING tasking, KHE_OPTIONS options);
}
calls @C { KheResourcePairReassign } for many pairs of resources.  The
@C { resource_invariant } arguments of all these calls are set to the
@C { resource_invariant } option of @C { options }.  Precisely what
@C { KheResourcePairRepair } does depends on the @C { resource_pair }
option of @C { options }, which has type @C { KHE_OPTIONS_RESOURCE_PAIR }:
@ID @C {
typedef enum {
  KHE_OPTIONS_RESOURCE_PAIR_NONE,
  KHE_OPTIONS_RESOURCE_PAIR_SPLITS,
  KHE_OPTIONS_RESOURCE_PAIR_PARTITIONS,
  KHE_OPTIONS_RESOURCE_PAIR_ALL
} KHE_OPTIONS_RESOURCE_PAIR;
}
If @C { resource_pair } is @C { KHE_OPTIONS_RESOURCE_PAIR_NONE },
it does nothing.
@PP
If @C { resource_pair } is @C { KHE_OPTIONS_RESOURCE_PAIR_SPLITS },
then for all pairs of distinct resources involved in all split
assignments of @C { tasking }, @C { KheResourcePairRepair } calls
@C { KheResourcePairReassign } for those two resources, with the
@C { fix_splits } parameter set to @C { true }.  These choices
focus the solver on repairing split assignments.
@PP
If the value of @C { resource_pair } is
@C { KHE_OPTIONS_RESOURCE_PAIR_PARTITIONS }, then
@C { KheResourcePairReassign } calls @C { KheResourcePairRepair }
for each pair of resources in each partition of the resource type
of @C { tasking }, or in all resource types if @C { tasking } has
no resource type, with the @C { fix_splits } parameter set to
@C { false }.  Each resource type with no partitions is treated as
though all resources lie in a single shared partitition.  These
choices focus the solver on improving resources' assignments
generally.  However the search space is often larger, increasing
the chance that the search will be cut short, losing optimality.
@PP
If @C { resource_pair } is @C { KHE_OPTIONS_RESOURCE_PAIR_ALL }, the
behaviour is the same as for @C { KHE_OPTIONS_RESOURCE_PAIR_PARTITIONS }
except that partitions are ignored, so that there is a call on
@C { KheResourcePairReassign } for every pair of distinct resources
of the types involved.
@PP
@C { KheResourcePairRepair } collects statistics about its calls to
@C { KheResourcePairReassign }, held in the @C { resource_pair_calls },
@C { resource_pair_successes }, and @C { resource_pair_truncs }
attributes of @C { options }.  Each time @C { KheResourcePairReassign }
is called, @C { resource_pair_calls } is incremented.  Each time it
returns @C { true }, @C { resource_pair_successes } is incremented.
And each time it truncates an overlong search (at most once per call),
@C { resource_pair_truncs } is incremented.  It is up to the caller
to make sure these options are initialized and retrieved at the
right moments, using the usual functions for retrieving and setting
options (Section {@NumberOf general_solvers.options.resource}).
@End @SubSection

@SubSection
    @Title { Partition graphs }
    @Tag { resource_solvers.pair.partition }
@Begin
@LP
Resource pair repair is essentially about two-colouring a clash
graph whose nodes are tasks and whose edges are pairs of tasks
that overlap in time.  Although the basic idea is simple enough,
the details become quite complicated, especially when optimizing
by removing symmetries in the search.  It has proved convenient to
build on a separate @I { partition graph } module, which is the
subject of this section.  It finds the connected components of a
graph (called @I { components } here), and, if requested,
partitions components into two @I { parts } by two-colouring them.
@PP
The module stores a graph whose nodes are represented by values
of type @C { void * }.  There are operations for creating and
deleting a graph, adding nodes to it, and visiting those nodes:
@ID @C {
KHE_PART_GRAPH KhePartGraphMake(KHE_PART_GRAPH_REL_FN rel_fn);
void KhePartGraphDelete(KHE_PART_GRAPH graph);
void KhePartGraphAddNode(KHE_PART_GRAPH graph, void *node);
int KhePartGraphNodeCount(KHE_PART_GRAPH graph);
void *KhePartGraphNode(KHE_PART_GRAPH graph, int i);
}
Deleting a graph includes deleting all its components and parts,
but not its nodes.  These functions and the others in this section
are declared in include file @C { khe_part_graph.h }.
@PP
To define the edges, the user passes in a @I { relation function }
of type @C { KHE_PART_GRAPH_REL_FN } which the module calls back
whenever it needs to know whether two nodes are connected by an
edge.  As the user would define it, this function looks like this:
@ID @C {
KHE_PART_GRAPH_REL RelationFn(void *node1, void *node2)
{
  ...
}
}
where type @C { KHE_PART_GRAPH_REL } is
@ID @C {
typedef enum {
  KHE_PART_GRAPH_UNRELATED,
  KHE_PART_GRAPH_DIFFERENT,
  KHE_PART_GRAPH_SAME
} KHE_PART_GRAPH_REL;
}
Values @C { KHE_PART_GRAPH_UNRELATED } and @C { KHE_PART_GRAPH_DIFFERENT }
are the usual options for clash graphs, the first saying that there is
no edge between the two nodes, the second that there is an edge which
requires the two nodes to be coloured with different colours.  The
third value, @C { KHE_PART_GRAPH_SAME }, says that the two nodes must
be coloured the same colour.  It is used, for example, when the two
nodes represent tasks which are linked by an avoid split assignments
constraint, and the @C { fix_splits } option is in force.
@PP
After all nodes have been added, the user may call
@ID @C {
void KhePartGraphFindConnectedComponents(KHE_PART_GRAPH graph);
}
to find the connected components, which may then be visited by
@ID {0.95 1.0} @Scale @C {
int KhePartGraphComponentCount(KHE_PART_GRAPH graph);
KHE_PART_GRAPH_COMPONENT KhePartGraphComponent(KHE_PART_GRAPH graph, int i);
}
The graph that a component is a component of may be found by
@ID {0.98 1.0} @Scale @C {
KHE_PART_GRAPH KhePartGraphComponentGraph(KHE_PART_GRAPH_COMPONENT comp);
}
and the nodes of a component may be visited by
@ID @C {
int KhePartGraphComponentNodeCount(KHE_PART_GRAPH_COMPONENT comp);
void *KhePartGraphComponentNode(KHE_PART_GRAPH_COMPONENT comp, int i);
}
@C { KhePartGraphFindConnectedComponents } considers two nodes to
be connected when @C { rel_fn } returns @C { KHE_PART_GRAPH_SAME }
or @C { KHE_PART_GRAPH_DIFFERENT } when passed those nodes.
@PP
If requested, the module will partition the nodes of a component
into two sets, such that two-colouring the component will give
the nodes in one set one colour, and the nodes in the other set
the other colour.  This gives exactly two ways to two-colour the
component, which is all there are, since once a colour is assigned
to one node, its neighbours must be assigned the other colour, their
neighbours must be assigned the first colour, and so on.  To carry
out this partitioning, call
@ID @C {
void KhePartGraphComponentFindParts(KHE_PART_GRAPH_COMPONENT comp);
}
After that, to retrieve the two parts, call
@ID @C {
bool KhePartGraphComponentParts(KHE_PART_GRAPH_COMPONENT comp,
  KHE_PART_GRAPH_PART *part1, KHE_PART_GRAPH_PART *part2);
}
If @C { KhePartGraphComponentFindParts } was able to partition
the component into two parts, @C { KhePartGraphComponentParts }
returns @C { true } and sets @C { *part1 } and @C { *part2 }
to non-@C { NULL } values; otherwise it returns @C { false }
and sets them to @C { NULL }.  To find a part's enclosing component,
call
@ID @C {
KHE_PART_GRAPH_COMPONENT KhePartGraphPartComponent(
  KHE_PART_GRAPH_PART part);
}
The nodes of a part may be visited by
@ID @C {
int KhePartGraphPartNodeCount(KHE_PART_GRAPH_PART part);
void *KhePartGraphPartNode(KHE_PART_GRAPH_PART part, int i);
}
as usual.
@End @SubSection

@SubSection
    @Title { The implementation of resource pair reassignment }
    @Tag { resource_solvers.pair.implementation }
@Begin
@LP
This section describes the implementation of @C { KheResourcePairReassign }.
It builds two partition graphs altogether, a @I { first graph } which
does the basic analysis, and a @I { second graph } which is used to
find and remove symmetries in the first graph.
@PP
The same node type is used in both graphs.  A node holds a set of
tasks.  A resource is @I { assignable to a node } when it is assignable
to each task of the node.  A resource is assignable to a fixed task
when it is assigned to that task (fixed tasks are never unassigned).
A resource is assignable to an unfixed task when it lies in the
domain of that task.  It is possible for neither, one, or both
resources to be assignable to a node.  If neither is assignable,
the node is @I { unassignable }, otherwise it is @I { assignable }.
@PP
When a resource is assignable to a node, there are operations for
assigning and unassigning it.  To assign it, assign it to each
unfixed task of the node.  To unassign it, unassign it from each
unfixed task of the node.
@PP
The first graph contains one node for each task initially assigned
@C { r1 } or @C { r2 }, containing just that task.  Thus, in the
first graph there are no unassignable nodes.  Given two nodes, the
first graph's relation function first checks which resources are
assignable to each.  If there is no way to assign the same resource
to both nodes, it returns @C { KHE_PART_GRAPH_DIFFERENT }.
Otherwise, if there is no way to assign different resources to the
nodes, it returns @C { KHE_PART_GRAPH_SAME }.  Otherwise, if
@C { fix_splits } is @C { true } and the two nodes share an
avoid split assignments monitor of non-zero cost, it returns
@C { KHE_PART_GRAPH_SAME }.  Otherwise, if the two nodes overlap
in time, it returns @C { KHE_PART_GRAPH_DIFFERENT }.  Otherwise
it returns @C { KHE_PART_GRAPH_UNRELATED }.
@PP
Next, the graph's connected components are found and partitioned.
It is easy to see, referring to the relation function, that if a
component was successfully partitioned there must be at least one
way (and possibly two ways) to assign @C { r1 } to the nodes of
one part and @C { r2 } to the nodes of the other part.  So a
component of the first graph is called @I { assignable } if it
was successfully partitioned, and @I { unassignable } otherwise.
@PP
For each assignable component, the nodes of one part are merged
into one node, and the nodes of the other are merged into a second
node.  These two nodes are assignable to different resources in one
or two ways.  For each unassignable component, all the nodes are
merged into a single node.  It does not matter whether this node
is assignable or not; it is never assigned.
@PP
Next, the assignable components are sorted into increasing order
of number of possible assignments.  Each of the @M { C } assignable
components has 1 or 2 possible assignments.  A tree search is carried
out which tries each of these on each component in turn.  The total
search space size is at most @M { 2 sup C }.  This is often small
enough to search completely.  For safety, the search only explores
both assignments until 512 tree nodes have been visited; after that
it tries only one assignment for each component.  In the usual way,
each time the tree search reaches a leaf it compares its solution
cost with the best so far, and if it is better (and if the resource
assignment invariant is preserved, if required) it takes a copy of
its decisions.  At the end, the cost of the best solution found is
compared with the initial solution cost, and if the best solution
is better it is installed; otherwise the initial solution is restored.
@PP
The search space often has symmetries which would waste time and
cause the node limit to be reached often enough to compromise
optimality in practice if they were not removed.  The rest of
this section describes them and how @C { KheResourcePairReassign }
removes them.
@PP
Suppose @C { r1 } and @C { r2 } are Mathematics teachers assigned to
two Mathematics courses from the same form, each split into 4
meets of the same durations, running simultaneously.  This gives 4
components and a search space of size @M { 2 sup 4 }, yet clearly
this could be reduced safely to 1.  If two of the simultaneous meets
are made not simultaneous, the search space size can still be reduced
safely, to 2.  If @C { fix_splits } is @C { true }, each set of 4
meets is related, making 1 component and a search space of size
2---still unnecessarily large when the meets are simultaneous.
@PP
A component is @I { symmetrical } if it makes no difference which
of its two assignments is chosen.  In that case, its assignment
choices can be reduced from 2 to 1 by arbitrarily removing one,
halving the search space size.  But note the complicating factor
in the Mathematics example:  one cannot arbitrarily remove one
choice from each component, because some combinations of choices
lead to split assignments and others do not.  Instead, a way must
be found to first merge the four components into one, which can
then be assigned arbitrarily.
@PP
Symmetry arises when the two assignment choices of a component
affect monitors in the same way.  They need to have the same
effect on the state of monitors, so that no difference arises
when the monitors change state again later in response to
changes outside the component.
@PP
The two choices always have the same effect on the state of event
monitors (no effect at all), and on the state of assign resources
monitors, which care only whether tasks are assigned resources,
not which resources.  As far as these kinds of monitors are
concerned, all components are symmetrical.  Classify the remaining
monitors into three groups:  resource monitors, prefer resources
monitors, and avoid split assignments monitors.
@PP
A component is @I { r-symmetrical }, @I { p-symmetrical }, or
@I { s-symmetrical } when it is assignable both ways and they
affect in the same way all resource, prefer resources, or avoid
split assignments monitors that monitor tasks of the component.
(In particular, if there are no monitors of some type, the
component is vacuously symmetrical in that type.)  Combinations
of prefixes denote conjunctions of these conditions.  For example,
@I { symmetrical } is shorthand for @I { rps-symmetrical }.
@PP
Although these definitions are clear in principle, they are rather
abstract.  An algorithm needs concrete, easily computable conditions
that imply the abstract ones and are likely to hold in practice.  Here
are the concrete conditions used by @C { KheResourcePairReassign },
assuming that the component is assignable both ways.
@PP
Suppose that some component's two parts run at the same times and have
the same total workload.  Then the component is r-symmetrical, because
only these things affect resource monitors, except clashes---but component
assignments have no clashes in themselves, and since the two parts
run at the same times, they have the same clashes with tasks outside
the component.
@PP
Suppose that, for every prefer resources monitor of non-zero cost
which monitors any task of some component, either @C { r1 } and
@C { r2 } are both preferred by the monitor's constraint, or they
are both not preferred.  Then the component is p-symmetrical.
@PP
Suppose that, for each task in some component @M { c } which is
monitored by an avoid split assignments monitor of non-zero cost,
every task monitored by that monitor either was not assigned
@C { r1 } or @C { r2 } originally, or else it lies in @M { c }.
Then the component is s-symmetrical.
@PP
To prove this, take one avoid split assignments monitor, and partition
the set of tasks monitored by it into those that were not assigned
@C { r1 } or @C { r2 } originally, and so are beyond the scope of the
reassignment (call them @M { S sub 1 }), and those that were (call
them @M { S sub 2 }).  If the tasks of @M { S sub 2 } lie within two
or more components, then which way those components are assigned does
matter.  But if they lie within one component, then the cost of the
monitor will be the same whichever assignment is chosen.  This is
because @C { r1 } and @C { r2 } do not appear among the resources
assigned to the tasks of @M { S sub 1 } (if they did, those tasks
would be in @M { S sub 2 }), so the assignments to @M { S sub 2 }
introduce fresh resources to the monitor.  If all the tasks of
@M { S sub 2 } lie in one part of the component, one fresh resource
is introduced by both assignments; if some lie in one part and the
others in the other, two fresh resources are introduced by both
assignments.  Either way, the effect on the monitor is the same.
@PP
When @C { fix_splits } is @C { true }, all tasks which share an
avoid split assignments monitor lie in the same part, so in the
same component.  So every component is s-symmetrical in that case.
@PP
It is easy to check whether a component is rp-symmetrical.  This
is done as each component is partitioned.  Merely checking for
s-symmetry is not enough:  as illustrated by the Mathematics
example, several components may need to be merged (by merging
their parts) to produce one s-symmetrical component.  This is
done using the second partitioning graph, as follows.
@PP
The second-graph nodes are the merged nodes from the first-graph
components.  When two nodes come from the same first-graph component,
@C { KHE_PART_GRAPH_DIFFERENT } is returned by the relation function.
Otherwise, if they share an avoid split assignments monitor of non-zero
cost, it returns @C { KHE_PART_GRAPH_SAME }.  Otherwise it returns
@C { KHE_PART_GRAPH_UNRELATED }.
# @PP
# The relation function works differently
# depending on whether the nodes come from assignable components
# or not.  If both nodes come from assignable components, then
# if they come from the same component
# function returns @C { KHE_PART_GRAPH_DIFFERENT } if they are fixed
# to different values, and @C { KHE_PART_GRAPH_SAME } if they are
# fixed to the same values.  Otherwise, if the two nodes come from
# the same old component, @C { KHE_PART_GRAPH_DIFFERENT } is returned.
# Otherwise, if they share an avoid split assignments monitor of 
# non-zero cost, the result is @C { KHE_PART_GRAPH_SAME }.  Otherwise
# the result is @C { KHE_PART_GRAPH_UNRELATED }.
# @PP
# If two nodes have different fixed assignments but also share an avoid
# split assignments constraint, there is a conflict.  The relation
# function returns @C { KHE_PART_GRAPH_DIFFERENT }, which amounts to
# ignoring the avoid split assignments constraint.  So the modelling is
# imperfect here, and the result of the tree search may be sub-optimal.
# However, this problem is very obscure and not worth worrying about:
# fixed assignments are rare, and @C { KheResourcePairReassign } does
# not promise to find an optimal reassignment in all cases anyway,
# because of the tree node limit.
@PP
Two nodes representing the two parts of a first-graph component must
lie in the same second-graph component, because there is an edge
between them.  So each second-graph component is a set of first-graph
components linked by avoid split assignments constraints.
@PP
For each second-graph component, its first-graph components may be
merged if it does not contain an unassignable first-graph component, at
most one of its first-graph components is not rp-symmetrical, and it is
partitionable.  The two nodes of the merged component are built by
merging the nodes of each part of the second-graph component.  If all
the first-graph components being merged are rp-symmetrical, the resulting
component is rps-symmetrical, so either one of its assignments may be
removed.  But component merges are valuable even without rps-symmetry.
@End @SubSection

@EndSubSections
@End @Section

@Section
    @Title { Resource rematching }
    @Tag { resource_solvers.rematch }
@Begin
@LP
Function
@ID @C {
bool KheResourceRematch(KHE_TASKING tasking, KHE_OPTIONS options);
}
repairs the assignments of the tasks of @C { tasking } as follows.
@PP
Take each task @M { t sub k } of @C { tasking } which is either
unassigned, or assigned an unpreferred resource, or part of a
split assignment, or involved in a clash.  Let @M { s sub k } be
the set of times that @M { t sub k } is running.  Build the set
@M { S } of all distinct (not necessarily disjoint) such sets of
times @M { s sub k }.
@PP
The algorithm works for any set of times @M { s sub k }, but it is
only tried on the sets of times @M { s sub k } in @M { S }, because
only those offer any realistic prospect of improvement.  For each
such set of times @M { s sub k }, then, the algorithm proceeds as
follows.
@PP
Build a bipartite graph as follows.  There is one supply node for
each resource @M { r sub i } (or each resource @M { r sub i } of type
@C { KheTaskingResourceType(tasking) }, if that is non-@C { NULL }).
There is one demand node for each of these resources @M { r sub i },
containing the set of tasks @M { T sub i } which lie in
@C { tasking }, overlap @M { s sub k } in time, and are assigned
to @M { r sub i }.  In addition, for each unassigned individual
task which lies in @C { tasking } and overlaps @M { s sub k } in
time there is one demand node containing that task.
@PP
Unassign all tasks in all demand nodes.  Join a supply node @M { s }
to a demand node @M { d } when @M { s }'s resource can be assigned
to all of the tasks of @M { d }, and weight the edge by the cost
of the solution when that is done.  Find a matching in this graph
of maximum size and minimum total weight, and use it to reassign
all the tasks.  If the resulting solution has smaller cost than
the original, use it; otherwise return to the original solution.
@PP
Rematching methods are often inexact @Cite { $post2011cyclic }, but
the reassignment found by this rematching is optimal, assuming that
assigning is always better than not assigning.  This can be seen by
a careful examination of the 16 constraint types:  each is either
unaffected by the reassignment, or else its effect is independent
for each resource"/"task pair, proving that the weights of the edges
of any matching are valid in combination as well as individually.
@End @Section

@Section
    @Title { Trying unassignments }
    @Tag { resource_solvers.unassignments }
@Begin
@LP
KHE's solvers assume that it is always a good thing to assign a
resource to a task.  However, occasionally there are cases where
cost can be reduced by unassigning a task, because the cost of the
resulting assign resource defect is less than the cost of the defects
introduced by the assignment.  As some acknowledgement of these
anomalous cases, KHE offers
@ID @C {
bool KheSolnTryTaskUnAssignments(KHE_SOLN soln);
}
for use at the end.  It tries unassigning each task of @C { soln }
in turn.  If any unassignment reduces the cost of @C { soln }, it
is not reassigned.  The result is @C { true } if any unassignments
were kept.
@End @Section

@Section
    @Title { Putting it all together }
    @Tag { resource_solvers.all_together }
@Begin
@LP
Three decisions face the designer of a resource solver.  Should the
solver work with split assignments, or with unsplit ones?  Should it
preserve the resource assignment invariant, or not?  Should it respect
the domains of tasks, or not?  Fortunately, KHE makes it easy to write
solvers that can be used with any combination of these three decisions,
as follows.
@PP
Get unsplit assignments by building a task tree with avoid split
assignments jobs.  Allow split assignments by calling
@C { KheTaskingAllowSplitAssignments }
(Section {@NumberOf resource_solvers.task_tree.reorganization}).
Either way, the solver assigns resources to unfixed tasks, without
knowing or caring if they have followers.
@PP
By enclosing each attempt to change the solution in
@C { KheAtomicTransactionBegin } and @C { KheAtomicTransactionEnd }
(Section {@NumberOf resource_solvers.invt}), a solver can preserve the
resource assignment invariant, or not, depending on the value of a
Boolean parameter.
# Most of the pre-packaged solvers lack this parameter;
# they always preserve the invariant.
@PP
If domains are to be respected, do nothing; if not, then before
running the solver, call @C { KheTaskingEnlargeDomains }
(Section {@NumberOf resource_solvers.task_tree.reorganization })
to enlarge them to the full set of resources.
@PP
A sequence of three functions,
@ID @C {
bool KheTaskingAssignResourcesStage1(KHE_TASKING tasking,
  KHE_OPTIONS options);
bool KheTaskingAssignResourcesStage2(KHE_TASKING tasking,
  KHE_OPTIONS options);
bool KheTaskingAssignResourcesStage3(KHE_TASKING tasking,
  KHE_OPTIONS options);
}
packages this chapter's ideas into a three-stage solver which assigns
resources to the tasks of @C { tasking }.  Called in order, they take
a `progressive corruption' approach to the decisions just described:
they are spotless at first, but they slide into the gutter towards the
end.
@PP
@C { KheTaskingAssignResourcesStage1 } first ensures that domains and
assignments take account of all constraints:
@ID @C {
KheOptionsSetResourceInvariant(options, true);
tjt = KHE_TASK_JOB_HARD_PRC | KHE_TASK_JOB_SOFT_PRC |
      KHE_TASK_JOB_HARD_ASAC | KHE_TASK_JOB_SOFT_ASAC;
KheTaskingMakeTaskTree(tasking, tjt, NULL, options);
}
Then it assigns resources to the unassigned unfixed tasks of
@C { tasking }, using resource packing if there are avoid split
assignments constraints, and the simpler most constrained first
algorithm otherwise.  This is followed by an ejection chain repair
algorithm:
@ID @C {
rt = KheTaskingResourceType(tasking);
if( rt == NULL || KheResourceTypeAvoidSplitAssignmentsCount(rt) > 0 )
  KheResourcePackAssignResources(tasking, options);
else
  KheMostConstrainedFirstAssignResources(tasking, options);
KheEjectionChainRepairResources(tasking, options);
}
So far, there are no split assignments, the resource assignment
invariant is preserved, and domains are respected.  The great
majority of the tasks, probably, have been assigned resources.
@PP
@C { KheTaskingAssignResourcesStage2 } calls
@C { KheFindSplitResourceAssignments } to build split assignments,
and @C { KheTaskingAllowSplitAssignments } to permit all tasks,
assigned or not, to be split.  It then carries out ejection
chain, rematching, and resource pair repairs:
@ID @C {
rt = KheTaskingResourceType(tasking);
if( KheResourceTypeAvoidSplitAssignmentsCount(rt) > 0 )
{
  KheFindSplitResourceAssignments(tasking, options);
  KheTaskingAllowSplitAssignments(tasking, false);
  KheEjectionChainRepairResources(tasking, options);
  if( KheOptionsResourceRematch(options) )
    KheResourceRematch(tasking, options);
  KheResourcePairRepair(tasking, options);
}
}
Since there are split assignments now, the ejection chain algorithm will
try to unsplit them (it has always had an augment function for this, but
there have been no split assignments to trigger it until now).  It also
tries to assign unassigned tasks, even at the cost of splitting assignments
that were previously unsplit.  The calls to @C { KheResourceRematch }
and @C { KheResourcePairRepair } only act when permitted by the
relevant options (Section {@NumberOf general_solvers.options}).
@PP
@C { KheTaskingAssignResourcesStage3 } is very corrupt indeed:
@ID @C {
KheOptionsSetResourceInvariant(options, false);
KheTaskingEnlargeDomains(tasking, true);
KheEjectionChainRepairResources(tasking, options);
}
The domains of the remaining unassigned tasks are enlarged to the
full resource type using @C { KheTaskingEnlargeDomains }, and the
ejection chain algorithm is run yet again, this time without
preserving the resource assignment invariant.  Enlarging domains
makes sense only at the very end, and will make a difference only
if any room or any teacher is better than none.  Because of the
removal of the invariant, this stage should be run only after the
first two stages have been run for each resource type.
@End @Section

@EndSections
@End @Chapter
