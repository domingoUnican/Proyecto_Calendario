@Appendix
    @Title { Implementation Notes }
    @Tag { impl }
@Begin
This appendix documents aspects of the implementation of KHE.  It
is included mainly for the author's own reference; it is not needed
for using KHE.
@BeginSubAppendices

@SubAppendix
    @Title { Source file organization }
    @Tag { impl.organizing }
@Begin
@LP
The KHE platform is organized in object-oriented style, with one
C source file for each major type.  A type's internals are visible
only within its file, so that all access to them is via functions.
Headers for some of these functions appear in @C { khe.h }, making
them available to the end user.  Headers for others appear in
@C { khe_interns.h }, making them available only to the platform.
@PP
Although this section applies to all source files, it is motivated
by the problems of organizing the source files of types defining
parts of solutions.  Some of these are quite large.  For example,
@C { khe_meet.c }, which holds the internals of type @C { KHE_MEET },
is over 5000 lines.
@PP
There is a canonical order for the types representing parts of
solutions:  @C { KHE_SOLN }, @C { KHE_MEET }, @C { KHE_MEET_BOUND },
@C { KHE_TASK }, @C { KHE_TASK_BOUND }, @C { KHE_MARK }, @C { KHE_PATH },
@C { KHE_NODE }, @C { KHE_LAYER }, @C { KHE_ZONE }, @C { KHE_TASKING }.
The idea is to handle these types in this order whenever appropriate---in
this Guide for example.
@PP
Source files are organized internally by dividing them into
@I { submodules }, which are segments of the files separated by
comments.  Each submodule handles one aspect of the type.  Here
is a generic list of the submodules appearing in any one file,
in their order of appearance:
@ID @OneRow @I lines @Break {
Type declaration
Simple attributes (back pointers, visit numbers, etc.)
Creation and deletion
Relations with objects of the same type (copy, split, etc.)
Relations with objects of different types
File reading and writing
Debug
}
Simple attributes are easily handled attributes that are not closely
related to any following categories.  They may appear in separate
submodules, or be grouped into one submodule.  Each relation is one
submodule (counting opposite operations, such as split and merge, as part
of one relation), except that a large relation may be broken into several
submodules.  Relations with different types appear in the canonical order
defined above.
# For example, the full list of submodules for meets is
# @ID @OneRow @I lines @Break {
# Type declaration
# Back pointers
# Visit numbers
# Other simple attributes
# Matchings (private)
# Creation and deletion
# Copy
# Domain calculations (private)
# Split and merge
# Assignment (basic functions)
# Assignment (helper functions)
# Assignment (queries)
# Assignment (fixing and unfixing)
# Cycle meets and time assignment
# Meet domains and bounds
# Meet domains and bounds (automatic domains)
# Tasks
# Nodes
# Zones
# File reading and writing
# Debug
# }
@PP
An attempt has been made to keep the submodules in the same order as
their functions are presented in this Guide, except for debugging.
Some submodules have no defined position according to this rule,
because they are present only to support other submodules, and
offer no functions to the end user.  Those are placed where they
seem to fit best.
@End @SubAppendix

@SubAppendix
    @Title { Relations between objects }
    @Tag { impl.relation }
@Begin
@LP
This section explains how KHE maintains relations between objects.
Not every relation is maintained as explained here, but it is the
author's aim to achieve that in time.
@PP
The most common relation, by far, is the @I { one-to-many }
relation, in which one object is related to any number of
objects of the same or another type:  one node contains any
number of meets, one meet contains any number of tasks, one
meet is assigned any number of meets, and so on.
@PP
Let @C { KHE_A } be the type of the entity that there is one of,
and @C { KHE_B } be the type of the entity that there are many of.
KHE implements the relation by placing one attribute, of type
@C { ARRAY_KHE_B }, in @C { KHE_A }, holding the many @C { KHE_B }
objects related to @C { KHE_A }, and two in @C { KHE_B }:
@ID @C {
KHE_A	a;
int	a_index;
}
holding the one @C { KHE_A } object related to this object, and
this object's index in that object's array.  Any attributes of
the relation, such as the offset attribute of the meet assignment
relation, appear alongside these two.  In the @C { KHE_A } class
file, functions
@ID @C {
void KheAAddB(KHE_A a, KHE_B b);
void KheADeleteB(KHE_A a, KHE_B b);
}
are defined which add and delete elements of the relation, as
well as the usual @C { KheABCount } and @C { KheAB } functions
which iterate over the array.  In the @C { KHE_B } class file,
functions
@ID @C {
KHE_A KheBA(KHE_B b);
void KheBSetA(KHE_B b, KHE_A a);
int KheBAIndex(KHE_B b);
void KheBSetAIndex(KHE_B b, int a_index);
}
get and set the @C { a } and @C { a_index } attributes of @C { b },
supporting constant time deletions.  Instead of searching for @C { b }
in @C { a }'s array, @C { a_index } is used to find it directly.
It is overwritten by the entity at the end of the array, whose
index is then changed.  This assumes that the order of the array's
elements may be arbitrary, as is usually the case.  The setter
functions are private to the platform.
@PP
This plan allows a @C { KHE_B } object to be unrelated to any
@C { KHE_A } object (just set its @C { a } attribute to @C { NULL }),
but does not support @I { many-to-many } relations, where a
@C { KHE_B } object may be related to any number of @C { KHE_A }
objects.  On the rare occasions when KHE needs this kind of relation,
it adapts the familiar edge lists implementation of graphs:  it
defines a type @C { KHE_A_REL_B } representing one element of the
many-to-many relation, and installs one one-to-many relation from
@C { KHE_A } to @C { KHE_A_REL_B }, and another from @C { KHE_B }
to @C { KHE_A_REL_B }.  This gives @C { KHE_A_REL_B } attributes
@ID @C {
KHE_A	a;
int	a_index;
KHE_B	b;
int	b_index;
}
and places it in arrays in both @C { entity_a } and @C { entity_b }.
Now the operations for adding and deleting an element of the relation
must add or delete two one-to-many relations, as well as creating
or deleting one @C { KHE_A_REL_B } object, which is done using a
free list to save time.
@End @SubAppendix

@SubAppendix
    @Title { Kernel operations }
    @Tag { impl.kernel }
@Begin
@LP
The promises made in connection with marks and paths, that all
operations that change a solution can be undone (except changes to
visit numbers), and that undoing a deletion recreates the object at its
original address, have significant implications for the implementation.
@PP
The KHE platform has an inner layer called the @I { solution kernel },
or just the @I { kernel }, consisting of a set of private operations,
called @I { kernel operations }, which change a solution.  Each
kernel operation has a name of the form @C { KheEntityKernelOp },
where @C { Entity } is the data type and @C { Op } is the operation.
It is the kernel operations that are stored in paths.  All operations
(except operations on visit numbers) change the solution only by
calling kernel operations, so if those are correctly done, undone,
and redone, all operations will be correctly done, undone, and redone.
@PP
For the record, here is the complete list of kernel operations:
@ID @OneRow {
@C {
KheMeetKernelSetBack
KheMeetKernelAdd
KheMeetKernelDelete
KheMeetKernelSplit
KheMeetKernelMerge
KheMeetKernelMove
KheMeetKernelAssignFix
KheMeetKernelAssignUnFix
KheMeetKernelAddMeetBound
KheMeetKernelDeleteMeetBound
KheMeetKernelSetAutoDomain

KheMeetBoundKernelAdd
KheMeetBoundKernelDelete
KheMeetBoundKernelAddTimeGroup
KheMeetBoundKernelDeleteTimeGroup

KheLayerKernelSetBack
KheLayerKernelAdd
KheLayerKernelDelete
KheLayerKernelAddChildNode
KheLayerKernelDeleteChildNode
KheLayerKernelAddResource
KheLayerKernelDeleteResource
}
|0.5c
@C {
KheTaskKernelSetBack
KheTaskKernelAdd
KheTaskKernelDelete
KheTaskKernelSplit
KheTaskKernelMerge
KheTaskKernelMove
KheTaskKernelAssignFix
KheTaskKernelAssignUnFix
KheTaskKernelAddTaskBound
KheTaskKernelDeleteTaskBound


KheTaskBoundKernelAdd
KheTaskBoundKernelDelete

KheNodeKernelSetBack
KheNodeKernelAdd
KheNodeKernelDelete
KheNodeKernelAddParent
KheNodeKernelDeleteParent
KheNodeKernelSwapChildNodesAndLayers
KheNodeKernelAddMeet
KheNodeKernelDeleteMeet

KheZoneKernelSetBack
KheZoneKernelAdd
KheZoneKernelDelete
KheZoneKernelAddMeetOffset
KheZoneKernelDeleteMeetOffset
}
}
Each @C { KheEntityKernelOp } function has a companion
@C { KheEntityKernelOpUndo } function.  @C { KheEntityKernelOp }
carries out its operation and adds itself to the solution's path, if
present.  @C { KheEntityKernelOpUndo } undoes what @C { KheEntityKernelOp }
did, only without removing itself from the solution's path, since
it is called by a function that has already done that.
@PP
A redo must be identical to the original operation, because both can be
inverted by calling @C { KheEntityKernelOpUndo } and removing one record
from the solution path.  So there are no @C { KheEntityKernelOpRedo }
functions; @C { KheEntityKernelOp } functions are called instead.
@PP
Some operations come in opposing pairs (split and merge, fix and
unfix, and so on), such that doing one is the same as undoing the
other, except that a do or redo adds a record to the solution's path,
whereas an undo does not.  In these cases the implementation contains
one private function called @C { KheEntityDoOp1 } and another called
@C { KheEntityDoOp2 }, where @C { Op1 } and @C { Op2 } are opposing
pairs.  These functions carry out the two operations without touching
the solution's path.  Then @C { KheEntityKernelOp1 },
@C { KheEntityKernelOp2 }, @C { KheEntityKernelOp1Undo }, and
@C { KheEntityKernelOp2Undo } are each implemented by one call on
@C { KheEntityDoOp1 } or @C { KheEntityDoOp2 }, plus an addition
to the solution's path if the operation is not @C { Undo }.
@PP
Operations that create and delete objects are awkward, as it turns
out, so the rest of this section is devoted to them.  The meet split
and merge operations are particularly awkward, so we will start with
the regular creation and deletion operations, generically named
@C { KheEntityMake } and @C { KheEntityDelete }, and treat meet
splitting and merging afterwards.
@PP
Solution objects are recycled through free lists held in the enclosing
solution.  When a new object is needed, it is taken from the free list,
or from the memory allocator if the free list is empty.  When an
object is no longer needed, it is added to the free list.  When the
solution is deleted, and only then, the objects on the free list are
returned to the memory allocator.  Free lists save time handling
extensible arrays within objects:  the arrays of a free list object
remain initialized.
@PP
An operation which obtains a new object from a memory allocator or
free list cannot be a kernel operation, because then a redo would not
re-create the object at its previous memory location.  An operation
which returns an object to a memory allocator or free list cannot be
a kernel operation, because an undo would not re-create the object at
its previous memory location.  So only the part of @C { KheEntityMake }
which initializes the object and links it into the solution is the
kernel operation, and only the part of @C { KheEntityDelete } which
unlinks the object from the solution is the kernel operation.  This
leads to this picture of the life cycle of a kernel object:
@CD @I @Diag vstrut { yes } margin { 0.15c } {
//0.5c
AA:: @Ellipse outlinestyle { dotted } hsize { 2.0c } @I { nonexist }
&2c
BB:: @Ellipse hsize { 2.0c } @I { freelist }
&2c
CC:: @Ellipse hsize { 2.0c } @I { unlinked }
&2c
DD:: @Ellipse hsize { 2.0c } @I { linked }
//0.5c
@CCurveArrow bias { 0.5c } from { AA } to { BB }
  ylabel { @C { KheEntityDoMake } }
@CCurveArrow bias { 0.5c } from { BB } to { AA } ylabelprox { below }
  ylabel { @C { KheEntityUnMake } }
@CCurveArrow bias { 0.5c } from { BB } to { CC }
  ylabel { @C { KheEntityDoGet } }
@CCurveArrow bias { 0.5c } from { CC } to { BB } ylabelprox { below }
  ylabel { @C { KheEntityUnGet } }
@CCurveArrow bias { 0.5c } from { CC } to { DD }
  ylabel { @C { KheEntityDoAdd } }
@CCurveArrow bias { 0.5c } from { DD } to { CC } ylabelprox { below }
  ylabel { @C { KheEntityUnAdd } }
}
State @I nonexist means that the object does not exist; @I freelist
means that it exists on a free list; @I unlinked means that it exists,
not on a free list, not linked to the solution, but referenced from
somewhere on some path; and @I linked means that it exists and is
linked to the solution.
@PP
@C { KheEntityDoMake } obtains a fresh object from the memory
allocator and initializes its private arrays.  @C { KheEntityUnMake }
does the opposite, returning the memory consumed by the object and
its private arrays to the memory allocator.
@PP
@C { KheEntityDoGet } obtains a fresh object from the free list, or
from @C { KheEntityDoMake } if the free list is empty.  Either way,
the object's arrays are initialized, although not necessarily empty.
Objects returned by @C { KheEntityDoMake } do not actually enter the
free list.  @C { KheEntityUnGet } does the opposite, adding the object
it is given to the free list.  It does not call @C { KheEntityUnMake }.
@PP
@C { KheEntityDoAdd } initializes the unlinked object it is given,
assuming that its private arrays are initialized, although not
necessarily empty (it clears them), and links it into the solution.
@C { KheEntityUnAdd } does the opposite, unlinking the object it
is given from the solution.
@PP
The kernel operations @C { KheEntityKernelAdd } and
@C { KheEntityKernelDelete } and their @C { Undo } companions are each
implemented by one call to @C { KheEntityDoAdd } or @C { KheEntityUnAdd },
plus an addition to the solution path if the function is not an undo.
@C { KheEntityKernelAdd } and @C { KheEntityKernelDelete } form an
opposing pair, as defined above, except that @C { KheEntityKernelDelete }
may include a call to @C { KheEntityUnGet } as explained below.
@PP
The public function that creates a kernel object, @C { KheEntityMake },
is @C { KheEntityDoGet } followed by @C { KheEntityKernelAdd }.  The
public function that deletes one, @C { KheEntityDelete }, begins with
kernel operations that help to unlink the object (unassignments and so
on), then ends with @C { KheEntityKernelDelete }.
@PP
These functions do not call @C { KheEntityUnMake }, since kernel
objects are returned to the memory allocator only when the entire
solution is deleted.  The function for deleting a solution first
calls user functions which delete all kernel objects and paths.
This places all kernel objects on the free list.  It then traverses
that list, passing each object to @C { KheEntityUnMake }.
@PP
An object can be referenced from the solution and from paths, and there
is no simple rule saying when to call @C { KheEntityUnGet } to add it
to the free list.  To solve this problem, an integer reference count
field is placed in each kernel object, counting the number of references
to the object.  Not all references are counted.  References from paths
at points where the object is added or deleted are counted.  For example,
in a path's record of a meet split or merge, the reference to the second
meet is counted, but not the first.  So reference counts increase when
paths grow or are copied, and decrease when paths shrink or are deleted.
Also, @C { KheEntityDoAdd } adds 1 to the count, and @C { KheEntityUnAdd }
subtracts 1.  This summarizes references from the solution generally in
one unit of the count.
@PP
When the reference count falls to zero, @C { KheEntityUnGet } is called
to return the object to the free list.  This could happen during a call
to @C { KheEntityUnAdd }, or when a path shrinks:  during a call to
@C { KhePathDelete }, or while undoing, which shrinks the solution's
main path.
@PP
An @I unlinked object could have come from the free list, and so
could contain no useful information.  It would be a mistake for
@C { KheEntityDoAdd } to assume that the object it is given has
passed through @C { KheEntityUnAdd } and retains useful information
from when it was previously linked.  Instead, @C { KheEntityDoAdd }
must initialize every field of the object it is given, assuming that its
arrays are initialized, but not that they contain useful information.
@PP
An example of getting this wrong would be to try to preserve the list
of tasks of a meet in its @C { tasks } array when it is unlinked, in
a mistaken attempt to ensure that they remain available for when the
meet is recreated.  What really happens is that before deleting the
meet, @C { KheMeetDelete } deletes its tasks, so records of those task
deletions appear on the solution path just before the meet deletion.
When an undo recreates the meet, it immediately goes on to recreate the
tasks, without any need for their preservation in the dormant meet.
@PP
A meet split is similar to a creation of the second meet, and a
meet merge is similar to a deletion of the second meet.  The main
new problem is that tasks need to be split and merged too.  So
separate kernel operations are defined for splitting the meet
itself and for splitting one of its tasks, and conversely for
merging two meets and for merging two of their tasks.  The
user operation for meet splitting does a kernel meet split
followed by a sequence of kernel task splits, and the user
operation for meet merging does the opposite.
@PP
The key advantage of doing it this way is that tasks are stored
explicitly in paths, and their reference counters take account
of this.  So the usual method of handling the allocation and
deallocation of entities generally, described above, applies
without change to the tasks created and deleted by meet splitting
and merging.
@PP
Meet bounds are related to meets in much the same way as tasks
are.  Once again, the kernel meet split operation does not make
meet bounds for the split-off meet; instead, they are made by
separate kernel meet bound creation operations, and thus will
be undone before a meet split is undone.  Similarly, task 
@PP
Paths have negligible time cost compared with the operations they
record; and their space cost is moderate, provided they are not used
to record wandering methods like tabu search.  Reference counting as
implemented here also costs very little:  in time, a few simple steps,
only carried out when creating or deleting a kernel object, not each time
the object is referenced; and in space, one integer per kernel object.
@End @SubAppendix

@SubAppendix
    @Title { Monitor updating }
    @Tag { impl.monitor_updating }
@Begin
@LP
When the user executes an operation that changes the state of a
solution, KHE works out the revised cost.  For efficiency, this
must be done incrementally.  This section explains how it is
done---but just for information:  the functions defined here
cannot be called by the user.
@PP
The monitors are linked into a network that allows state changing
operations to flow naturally to where they need to go.  Only
attached monitors are linked in; detached ones are removed, so
that no time is wasted on them.  The full list of basic operations
that affect cost is
@ID @Tbl
  aformat { @Cell ml { 0i } A | @Cell B | @Cell mr { 0i } C }
{
@Rowa
    A { @C {
KheMeetMake
KheMeetDelete
KheMeetSplit
} }
    B { @C {
KheMeetMerge
KheMeetAssign
KheMeetUnAssign
} }
    C { @C {
KheTaskMake
KheTaskDelete
KheTaskAssign
KheTaskUnAssign
} }
}
Six originate in @C { KHE_MEET } objects, four in
@C { KHE_TASK } objects.  From there their impulses flow
to objects of three private types:
@CD @OneRow 0.95 @Scale @Diag linklabelbreak { ragged -4px } {
@Tbl
    indent { ctr }
    aformat { @Cell ml { 0i } mr { 6c } A | @Cell mr { 0i } B }
{
@Rowa
    ma { 3c }
    A { SE::  @Box @C { KHE_MEET } }
    B { ES::  @Box @C { KHE_EVENT_IN_SOLN } }
@Rowa
    mv { 2c }
    A { SR::  @Box @C { KHE_TASK } }
    B { ERS:: @Box @C { KHE_EVENT_RESOURCE_IN_SOLN } }
@Rowa
    B { RS::  @Box @C { KHE_RESOURCE_IN_SOLN } }
}
//
@Arrow from { SE@NW ++ {0 1c} } to { SE }
  xlabel { @C {
KheMeetMake
KheMeetDelete
KheMeetSplit
KheMeetMerge
KheMeetAssign
KheMeetUnAssign
  } }
@Arrow from { SE } to { SR }
  ylabel { @C {
Split
Merge
AssignTime
UnAssignTime
  } }
@Arrow from { SE } to { ES }
  ylabel { @C {
Add
Delete
Split
Merge
AssignTime
UnAssignTime
  } }
@Arrow from { SR } to { ERS }
  ylabel { @C {
Add
Delete
Split
Merge
AssignResource
UnAssignResource
  } }
@Arrow from { SR } to { RS }
  ylabelmargin { 0i }
  ylabelprox { below }
  ylabeladjust { 0.2c 0.5c }
  ylabel { @C {
Split
Merge
AssignTime
UnAssignTime
AssignResource
UnAssignResource
  } }
@Arrow from { SR@SW -- {0 1c} } to { SR }
  xlabelprox { below }
  xlabel { @C {
KheTaskMake
KheTaskDelete
KheTaskAssign
KheTaskUnAssign
} }
}
@C { KHE_EVENT_IN_SOLN } holds information about one event in a
solution:  the meets derived from it (where
@C { KheEventMeet } gets its values from), a list of `event
resource in solution' objects, one for each of its event resources,
and a list of monitors, possibly including a timetable
(timetables are monitors).  @C { KHE_EVENT_RESOURCE_IN_SOLN }
holds information about one event resource in a solution:  the
tasks derived from it, and a list of monitors.
@C { KHE_RESOURCE_IN_SOLN } holds information about one resource
in a solution:  the tasks it is currently assigned to,
and a list of monitors, usually including a timetable.
@PP
The connections are fairly self-evident.  For example, if
@C { KheMeetMake } is called to make a meet derived from a given
instance event, then that event's event in solution object needs
to know this, and the @C { Add } operation (full name
@C { KheEventInSolnAddMeet }) informs it.  @C { KheMeetAssign }
only generates an @C { AssignTime } call when the assignment links
the meet, directly or indirectly, to a cycle meet, assigning a time
to it.  Event resource in solution objects are not told about time
assignments and unassignments.  Calls only pass from a task object
@C { task } to a resource in solution object when @C { task } is
assigned a resource.
@PP
The connections leading out of @C { KHE_EVENT_IN_SOLN } are as follows:
@CD @OneRow @Diag linklabelbreak { ragged -4px } {
@Tbl
    # indent { ctr }
    aformat { @Cell ml { 0i } mr { 3c } A | @Cell mr { 0i } B }
{
@Rowa
    ma { 0.0c }
    A { ES::  @Box @C { KHE_EVENT_IN_SOLN } }
@Rowa
    ma { 1.5c }
    B { SEM:: @Box @C { KHE_SPLIT_EVENTS_MONITOR } }
@Rowa
    B { DSEM:: @Box @C { KHE_DISTRIBUTE_SPLIT_EVENTS_MONITOR } }
@Rowa
    B { ATM::  @Box @C { KHE_ASSIGN_TIME_MONITOR } }
@Rowa
    B { PTM::  @Box @C { KHE_PREFER_TIMES_MONITOR } }
@Rowa
    B { TT:: @Box @C { KHE_TIMETABLE_MONITOR } }
@Rowa
    B { SPEM:: @Box @C { KHE_SPREAD_EVENTS_MONITOR } }
@Rowa
    B { OEM:: @Box @C { KHE_ORDER_EVENTS_MONITOR } }
    mb { 0.0c }
}
//
@VHArrow from { ES@SE -- {0.5c 0} } to { SEM }
  xlabel { @C {
Add
Delete
Split
Merge
  } }
@VHArrow from { ES@SE -- {0.5c 0} } to { DSEM }
@VHArrow from { ES@SW ++ {0.5c 0} } to { ATM }
  xlabel { @C {
Add
Delete
Split
Merge
AssignTime
UnAssignTime
  } }
@VHArrow from { ES@SW ++ {0.5c 0} } to { PTM }
@VHArrow from { ES@SW ++ {0.5c 0} } to { TT }
@VHArrow from { ES@SW ++ {0.5c 0} } to { SPEM }
@VHArrow from { ES@SW ++ {0.5c 0} } to { OEM }
}
Split events and distribute split events monitors do not need to
know about time assignment and unassignment.  Based on the calls
they receive, they keep track of meet durations and
report cost accordingly.  Assign time and prefer times monitors
are even simpler; they report cost depending on whether the
meets reported to them are assigned times or not.
@PP
Event timetables are used by link events constraints, which need
to know the times when the event's meets are running,
ignoring clashes, which is just what timetables offer.
@PP
A spread events monitor is connected to the event in solution
objects corresponding to each of the events it is interested in.
It keeps track of how many meets from those events
collectively have starting times in each of its time groups, and
calculates deviations accordingly.  Spread events monitors are
not attached to timetables because, although their monitoring is
similar, there are significant differences:  spread events
monitor time groups come with upper and lower limits, making
them not sharable in general, and the quantity of interest is the
number of distinct meets that intersect each time group,
not the number of busy times calculated by the time group monitors
attached to timetables.
@PP
An order events monitor is connected to the two event in solution
objects corresponding to the two events it is interested in.
These keep track of the events' meets, including their number,
and the monitor itself keeps track of the number of unassigned
meets.  So determining whether both events have at least one
meet, and whether there are no unassigned meets, take constant
time.  If both conditions are satisfied, the monitor traverses
both sets of meets to calculate the deviation and cost when a
meet is added, deleted, or assigned a time.  (In practice,
events subject to order events constraints do not split, so this
too takes constant time.)  The other operations are faster:
unassigning a time produces cost 0, and splitting and merging
do not change the cost.
# @PP
# It might seem that spread events monitors could usefully be
# attached to timetables rather than directly to event in solution
# objects, especially since they analyse by time groups, which
# timetables supply in the form of time group monitors (see below).
# However, a closer look shows two significant differences:  spread
# events monitor time groups come with upper and lower limits,
# making them not sharable in general, and the quantity of interest
# is the number of distinct meets that intersect each time
# group (either in their starting times or at all), which is quite
# different from the number of busy times calculated by time group
# monitors.  In the end it seemed best to keep spread events monitors
# completely separate.
@PP
The connections leading out of @C { KHE_EVENT_RESOURCE_IN_SOLN } are
@CD @OneRow @Diag linklabelbreak { ragged -4px } {
@Tbl
    indent { ctr }
    aformat { @Cell ml { 0i } mr { 1.5c } A | @Cell mr { 0i } B }
{
@Rowa
    ma { 0.0c }
    A { ERS::  @Box @C { KHE_EVENT_RESOURCE_IN_SOLN } }
@Rowa
    ma { 2.5c }
    B { ARM:: @Box @C { KHE_ASSIGN_RESOURCE_MONITOR } }
@Rowa
    B { PRM:: @Box @C { KHE_PREFER_RESOURCES_MONITOR } }
@Rowa
    B { ASAM::  @Box @C { KHE_AVOID_SPLIT_ASSIGNMENTS_MONITOR } }
    mb { 0.0c }
}
//
@VHArrow from { ERS } to { ARM }
  xlabel { @C {
Add
Delete
Split
Merge
AssignResource
UnAssignResource
  } }
@VHArrow from { ERS } to { PRM }
@VHArrow from { ERS } to { ASAM }
}
None of these monitors cares about time assignments and unassignments.
Assign resource monitors and prefer resources monitors are very simple,
reporting cost depending on whether the tasks passed to
them are assigned or not.
@PP
An avoid split assignments monitor is connected to one event resource
in solution object for each event resource in its point of application.
It keeps track of a multiset of resources, one element for each assignment
to each task it is monitoring, and its cost depends on the
number of distinct resources in that multiset.
@PP
The connections leading out of @C { KHE_RESOURCE_IN_SOLN } are
@CD @OneRow @Diag linklabelbreak { ragged -4px } {
@Tbl
    indent { ctr }
    aformat { @Cell ml { 0i } mr { 1.5c } A | @Cell mr { 0i } B }
{
@Rowa
    ma { 0.0c }
    A { RS::  @Box @C { KHE_RESOURCE_IN_SOLN } }
@Rowa
    ma { 1.2c }
    B { LWM:: @Box @C { KHE_LIMIT_WORKLOAD_MONITOR } }
@Rowa
    B { TT:: @Box @C { KHE_TIMETABLE_MONITOR } }
    mb { 0.0c }
}
//
@VHArrow from { RS@SE -- {0.5c 0} } to { LWM }
  xlabel { @C {
AssignResource
UnAssignResource
  } }
@VHArrow from { RS@SW ++ {0.5c 0} } to { TT }
  xlabel { @C {
Split
Merge
AssignTime
UnAssignTime
AssignResource
UnAssignResource
  } }
}
Limit workload constraints do not need to know about time assignments,
evidently, but they also do not need to know about splits and merges,
since these do not change the total workload.
@PP
Calculating workloads is then very simple.  Each meet
receives a workload when it is created, and when a resource is
assigned, the workload limit monitors attached to its resource in
solution object are updated, and pass revised costs to the solution.
@PP
@C { KHE_TIMETABLE_MONITOR } receives many kinds of calls, some from
@C { KHE_EVENT_IN_SOLN } and others from @C { KHE_RESOURCE_IN_SOLN }.
However, since it monitors the timetable of a set of meets
with assigned times, all these can be mapped to just two incoming
operations, which we call @C { AddMeetAtTime } and
@C { DeleteMeetAtTime }.  For example, a split maps to one
@C { DeleteMeetAtTime } and two @C { AddMeetAtTime }
calls.  The outgoing operations are
@CD @OneRow @Diag linklabelbreak { ragged -4px } {
@Tbl
    indent { ctr }
    aformat { @Cell ml { 0i } mr { 1.5c } A | @Cell mr { 0i } B }
{
@Rowa
    ma { 0.0c }
    A { TT:: @Box { 0.8c @Wide {} & @C { KHE_TIMETABLE_MONITOR } & 0.8c @Wide {} } }
@Rowa
    ma { 0.6c }
    B { ACM:: @Box @C { KHE_AVOID_CLASHES_MONITOR } } 
@Rowa
    B { LEM:: @Box @C { KHE_LINK_EVENTS_MONITOR } }
@Rowa
    B { TGM:: @Box @C { KHE_TIME_GROUP_MONITOR } }
    mb { 0.0c }
}
//
@VHArrow from { TT@SE -- {0.5c 0} } to { ACM }
  xlabel { @C {
ChangeClashCount
Flush
  } }
@VHArrow from { TT@SW ++ {0.5c 0} } to { LEM }
  xlabel { @C {
AssignTimeNonClash
UnAssignTimeNonClash
Flush
  } }
@VHArrow from { TT@SW ++ {0.5c 0} } to { TGM }
}
An avoid clashes monitor is notified whenever the number of meets
at any one time increases to more than 1 or decreases from more than 1
(operation @C { ChangeClashCount } above).  It uses these notifications
to maintain its deviation.  It updates the solution when a @C { Flush }
is received from the timetable at the end of the operation.
@PP
The other monitors are attached to the timetable at each time they are
interested in, and are notified when one of those times becomes busy
(when its number of meets increases from 0 to 1) and when it
becomes free (when its number of meets decreases from 1 to 0),
by operations @C { AssignTimeNonClash } and @C { UnAssignTimeNonClash }
above.
@PP
A link events monitor is interested in all the times of all the
timetables of the events in its point of application.  It is
notified when any of these times becomes busy or free, and
uses that information to maintain, for each time, the number
of its events that are busy at each time.  Its deviation, also
maintained incrementally, is the number of times where some of
its events, but not all of them, are running.
# @FootNote {
# KHE offers a simple way to ensure that a link events constraint is
# never violated, assuming that all the events to be linked have the
# same duration.  Let the events to be linked be
# @M { e sub 1 , e sub 2 ,..., e sub n }, and
# suppose that their common duration is @M { d }.
# At the start of the solve, split each @M { e sub i } into @M { m }
# meets @M { s sub i1 , s sub i2 ,..., s sub im } of durations
# (in order) @M { d sub 1 , d sub 2 ,..., d sub m }, whose sum is
# @M { d }.  The choice of @M { m } and the @M { d sub j } will be
# informed by the split events and distribute split events constraints
# applicable to the @M { e sub i }, and is a separate matter.
# Suppose that @M { m } distinct @I { lead er meets }
# @M { l sub 1 , l sub 2 ,..., l sub m } can be found such that:
# @BulletList
# 
# @LI {
# For all @M { j }, the duration of @M { l sub j } is at least
# @M { d sub j };
# }
# 
# @LI {
# For all @M { j }, if @M { l sub j = s sub ij } for some @M { i },
# then all the other @M { s sub ij } are assigned to @M { l sub j }
# at the same offset (0 in this case);
# }
# 
# @LI {
# For all @M { j }, if @M { l sub j != s sub ij } for any @M { i },
# then @M { l sub j } is not equal to any meet of any
# @M { e sub i }, and all the @M { s sub ij } are assigned to
# @M { l sub j } at the same offset (not necessarily 0).
# }
# 
# @EndList
# Then, as long as the assignments in those @M { s sub ij } that are
# not lead ers remain in place, even if no times are assigned it is
# already clear that no violations of the link events constraint are
# possible, because the assignment of a time to a lead er meet of
# duration @M { d sub j } assigns the same time to one meet of
# duration @M { d sub j } of every @M { e sub i }.  In these cases, the 
# link events monitors concerned should be detached.  They are expensive
# to keep up to date, yet only ever report cost 0.
# @PP
# @I { Not yet implemented. }  To support this style of solving,
# KHE offers @I { link locking }.  The user may request that a
# given link events monitor be link locked.  This causes KHE to
# verify that the current state of the assignments of the solution
# events of the events being monitored is as described above,
# including identifying a set of lead er meets.  It
# then locks all the assignments in the non-lead ers (i.e. makes it a
# fatal error to attempt to remove them), and detaches the link events
# monitor, so that no time will be wasted on it.
# Although a link
# lock can be removed at any time, link locking and unlocking are
# fairly slow operations.  Applying one link lock to each link events
# monitor at the start of the solve is fine, but frequent locking
# and unlocking during the solve, although legal, is not recommended.
# }
@PP
A time group monitor monitors one time group within one timetable.
It is attached to its timetable at the times of its time group, so
is notified when one of those times becomes busy or free.  It keeps
track of the number of busy and idle times in its time group.
@PP
As an optimization, the number of idle times is calculated only when
at least one limit idle times monitor is attached to the time group
monitor; otherwise the number is taken to be 0.  A bit vector @M { V },
holding the positions of the busy times in the time group being monitored,
is maintained.  When the monitor is flushed, the number of idle times
of @M { V } is calculated as follows.  If @M { V } is empty, there are
no idle times.  Otherwise, the number of idle times is
@ID @Math { max(V) - min(V) + 1 - "|" V "|" }
The first three terms give the total number of times from the
first busy time to the last inclusive; every non-busy time
within that range is an idle time and conversely.
@PP
@M { "|" V "|" } is just the number of busy times, always
maintained by the time group monitor, so it is readily available.
The calculation of @M { min(V) } and @M { max(V) } on a bit
vector is a well-known problem which never seems to attract
adequate hardware support.  KHE's bit vector module calculates
@M { min(V) } by a linear search for the first non-zero word
of the bit vector, followed by a linear search for the first
non-zero byte of that word, and finishing with a lookup in a
256-word table, indexed by that byte, which returns the position
of the first non-zero bit of that byte.  The same method,
searching in the other direction, finds @M { max(V) }.
@PP
Old and new values for the number of busy and idle times are
stored, and when a flush is received they are propagated
onwards via operation @C { ChangeBusyAndIdle }:
@CD @OneRow @Diag linklabelbreak { ragged -4px } {
@Tbl
    indent { ctr }
    aformat { @Cell ml { 0i } mr { 1.5c } A | @Cell mr { 0i } B }
{
@Rowa
    ma { 0.0c }
    A { TGM:: @Box @C { KHE_TIME_GROUP_MONITOR } }
@Rowa
    ma { 1.0c }
    B { AUTM:: @Box @C { KHE_AVOID_UNAVAILABLE_TIMES_MONITOR } }
@Rowa
    B { LITM:: @Box @C { KHE_LIMIT_IDLE_TIMES_MONITOR } } 
@Rowa
    B { CBTM:: @Box @C { KHE_CLUSTER_BUSY_TIMES_MONITOR } }
@Rowa
    B { LBTM:: @Box @C { KHE_LIMIT_BUSY_TIMES_MONITOR } }
    mb { 0.0c }
}
//
@VHArrow from { TGM } to { AUTM }
  xlabel { @C {
AddBusyAndIdle
DeleteBusyAndIdle
ChangeBusyAndIdle
  } }
@VHArrow from { TGM } to { LITM }
@VHArrow from { TGM } to { CBTM }
@VHArrow from { TGM } to { LBTM }
}
When a monitor is attached, function @C { AddBusyAndIdle } is called
instead, and when a monitor is detached, function @C { DeleteBusyAndIdle }
is called instead.
@PP
An unavailable times monitor is connected to a time group monitor
monitoring the unavailable times.  It receives an updated number
of busy times from @C { ChangeBusyAndIdle } and reports any
change of cost to the solution.
@PP
A limit idle times monitor is connected to the time group
monitors corresponding to the time groups of its constraint.
It receives updated idle counts from each of them, and based
on them it maintains its deviation.
@PP
A cluster busy times monitor is also connected to the time
group monitors corresponding to the time groups of its
constraint.  It is interested in whether the busy counts it
receives from them change from zero to non-zero, or conversely.
@PP
A limit busy times monitor is also connected to the time
group monitors corresponding to the time groups of its
constraint.  It receives updated busy counts from each of
them, and based on them it maintains its deviation.
@End @SubAppendix

@EndSubAppendices
@End @Appendix
